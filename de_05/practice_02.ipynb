{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95095395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from time import sleep, time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5204ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"articles_info.csv\" # имя файла, в который будем сохранять результат\n",
    "driver_path = \"./chromedriver.exe\" # укажите ваш путь к chromedriver, который вы загрузили ранее\n",
    "base_dir= \"./parse/\" # укажите директорию, в которую будем сохранять файл\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36\" # ваш user-agent, узнать его можно тут: https://юзерагент.рф, смотреть через браузер Chrome\n",
    "start_time = time() # время начала выполнения программы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c330a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_load_time(article_url, user_agent):\n",
    "    #будем ждать 3 секунды, иначе выводить exception и присваивать константное значение\n",
    "    try:\n",
    "        # меняем значение заголовка. По умолчанию указано, что это python-код\n",
    "        headers = {\n",
    "            \"User-Agent\": user_agent\n",
    "        }\n",
    "        # делаем запрос по url статьи article_url\n",
    "        response = requests.get(\n",
    "            article_url, headers=headers, stream=True, timeout=3.000\n",
    "        )\n",
    "        # получаем время загрузки страницы\n",
    "        load_time = response.elapsed.total_seconds()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        load_time = \">3\"\n",
    "    return load_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4900ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(output_list, filename, base_dir):\n",
    "    for row in output_list:\n",
    "        with open(Path(base_dir).joinpath(filename), \"a\") as csvfile:\n",
    "            fieldnames = [\"id\", \"load_time\", \"rank\", \"points\", \"title\", \"url\", 'comment']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a359a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_base(browser, page_number):\n",
    "    base_url = \"https://news.ycombinator.com/news?p={}\".format(page_number)\n",
    "    for connection_attempts in range(1,4): # совершаем 3 попытки подключения\n",
    "        try:\n",
    "            browser.get(base_url)\n",
    "            # ожидаем пока элемент table с id = 'hnmain' будет загружен на страницу\n",
    "            # затем функция вернет True иначе False \n",
    "            WebDriverWait(browser, 5).until(\n",
    "                EC.presence_of_element_located((By.ID, \"hnmain\"))\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error connecting to {}.\".format(base_url))\n",
    "            print(\"Attempt #{}.\".format(connection_attempts))\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a0a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html, user_agent):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    output_list = []\n",
    "   \n",
    "    # ищем в объекте soup object id, rank, score и title статьи\n",
    "    tr_blocks = soup.find_all(\"tr\", class_=\"athing\")\n",
    "    td_blocks = soup.find_all(\"td\", class_=\"subtext\")\n",
    "    article = 0\n",
    "    for i in range(len(tr_blocks)):\n",
    "        article_id = tr_blocks[i].get(\"id\") # id\n",
    "        article_url = tr_blocks[i].find_all(\"a\")[1][\"href\"]\n",
    "        article_comment = td_blocks[i].find_all(\"a\")[-1].text\n",
    "        if 'comments' in article_comment:\n",
    "            article_comment = int(article_comment.split()[0])\n",
    "        else:\n",
    "            article_comment = 0\n",
    "        \n",
    "        # print(article_comment)\n",
    "\n",
    "        # иногда статья располагается не на внешнем сайте, а на ycombinator\n",
    "        # тогда article_url у нее не полный, а добавочный, с параметрами.\n",
    "        # например item?id=200933. Для этих случаев будем добавлять url до полного\n",
    "        if \"item?id=\" in article_url or \"from?site=\" in article_url:\n",
    "            article_url = f\"https://news.ycombinator.com/{article_url}\"\n",
    "        load_time = get_load_time(article_url, user_agent)\n",
    "        # иногда рейтинга может не быть, поэтому воспользуемся try\n",
    "\n",
    "        try:\n",
    "            score = soup.find(id=f\"score_{article_id}\").string\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            score = \"0 points\"\n",
    "           \n",
    "        article_info = {\n",
    "            \"id\": article_id,\n",
    "            \"load_time\": load_time,\n",
    "            \"rank\": tr_blocks[i].span.string,\n",
    "            \"points\": score,\n",
    "            \"title\": tr_blocks[i].find(class_=\"titleline\").string,\n",
    "            \"url\": article_url,\n",
    "            'comment': article_comment,\n",
    "        }\n",
    "\n",
    "        # добавляем информацию о статье в список\n",
    "        output_list.append(article_info)\n",
    "        article += 1\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c878d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting page 0...\n",
      "getting page 1...\n",
      "getting page 2...\n",
      "HTTPSConnectionPool(host='phys.org', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.bbc.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='phys.org', port=443): Max retries exceeded with url: /news/2025-05-successful-quantum-error-qudits.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001ED276A6C10>, 'Connection to phys.org timed out. (connect timeout=3.0)'))\n",
      "HTTPSConnectionPool(host='www.youtube.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='cutfoldtemplates.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='btxx.org', port=443): Max retries exceeded with url: /posts/mail/ (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001ED276BA2D0>, 'Connection to btxx.org timed out. (connect timeout=3.0)'))\n",
      "getting page 3...\n",
      "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='raymii.org', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='btxx.org', port=443): Read timed out. (read timeout=3.0)\n",
      "getting page 4...\n",
      "'NoneType' object has no attribute 'string'\n",
      "HTTPSConnectionPool(host='engineering.fb.com', port=443): Read timed out. (read timeout=3.0)\n",
      "getting page 5...\n",
      "HTTPSConnectionPool(host='www.youtube.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.bbc.co.uk', port=443): Read timed out. (read timeout=3.0)\n",
      "getting page 6...\n",
      "HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='public.support.unisys.com', port=443): Max retries exceeded with url: /framework/publicterms.aspx?returnurl=%2Faseries%2Fdocs%2FClearPath-MCP-20.0%2F26211060-014%2FWebHelp%2FIntroduction_to_Security_Services%2FSecurity_Overview.htm (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001ED27B0E150>, 'Connection to public.support.unisys.com timed out. (connect timeout=3.0)'))\n",
      "getting page 7...\n",
      "HTTPSConnectionPool(host='www.youtube.com', port=443): Read timed out. (read timeout=3.0)\n",
      "getting page 8...\n",
      "HTTPSConnectionPool(host='twitter.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='sci-hub.se', port=443): Read timed out. (read timeout=3.0)\n",
      "getting page 9...\n",
      "run time: 237.88610219955444 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time() # время начала выполнения программы\n",
    "\n",
    "# инициализируем веб драйвер\n",
    "browser = webdriver.Chrome(\n",
    "    service=ChromeService(executable_path=driver_path)\n",
    ")\n",
    "\n",
    "# перебираем страницы и собираем нужную информацию\n",
    "for page_number in range(10):\n",
    "    print(\"getting page \" + str(page_number) + \"...\")\n",
    "    if connect_to_base(browser, page_number):\n",
    "        sleep(5)\n",
    "        output_list = parse_html(browser.page_source, user_agent)\n",
    "        write_to_file(output_list, filename, base_dir)\n",
    "\n",
    "    else:\n",
    "        print(\"Error connecting to hacker news\")\n",
    "\n",
    "# завершаем работу драйвера\n",
    "browser.close()\n",
    "sleep(1)\n",
    "browser.quit()\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"run time: {} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1da1688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='www.youtube.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='medium.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='twitter.com', port=443): Read timed out. (read timeout=3.0)\n",
      "'NoneType' object has no attribute 'string'\n",
      "HTTPSConnectionPool(host='apod.nasa.gov', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='sci-hub.se', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.bbc.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='engineering.fb.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.youtube.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='www.youtube.com', port=443): Read timed out. (read timeout=3.0)\n",
      "HTTPSConnectionPool(host='public.support.unisys.com', port=443): Max retries exceeded with url: /framework/publicterms.aspx?returnurl=%2Faseries%2Fdocs%2FClearPath-MCP-20.0%2F26211060-014%2FWebHelp%2FIntroduction_to_Security_Services%2FSecurity_Overview.htm (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000001ED2872F2D0>, 'Connection to public.support.unisys.com timed out. (connect timeout=3.0)'))\n",
      "HTTPSConnectionPool(host='www.bbc.co.uk', port=443): Read timed out. (read timeout=3.0)\n",
      "Elapsed run time: 42.53036308288574 seconds\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "\n",
    "# Обернём процедуру парсинга страницы в функцию\n",
    "def run_process(page_number, filename):\n",
    "    browser = webdriver.Chrome(\n",
    "        service=ChromeService(executable_path=driver_path)\n",
    "    )\n",
    "    if connect_to_base(browser, page_number):\n",
    "        sleep(5)\n",
    "        output_list = parse_html(browser.page_source, user_agent)\n",
    "        write_to_file(output_list, filename, base_dir)\n",
    "       \n",
    "        browser.quit()\n",
    "    else:\n",
    "        print(\"Error connecting to hacker news\")\n",
    "        browser.quit()\n",
    "       \n",
    "# Глобальные переменные        \n",
    "filename = \"articles_info_new.csv\" # имя файла, в который будем сохранять результат\n",
    "driver_path = \"./chromedriver.exe\" # укажите ваш путь к chromedriver, который вы загрузили ранее\n",
    "base_dir= \"./parse/\" # укажите директорию, в которую будем сохранять файл\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\"\n",
    "\n",
    "# Засечём время выполнения кода\n",
    "start_time = time()\n",
    "\n",
    "futures = []\n",
    "\n",
    "# Запустим процесс парсинга на нескольких потоках одновременно\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for number in range(10):\n",
    "        futures.append(\n",
    "            executor.submit(run_process, number, filename)\n",
    "        )\n",
    "       \n",
    "wait(futures)\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed run time: {} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1471b5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>load_time</th>\n",
       "      <th>rank</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44026799</td>\n",
       "      <td>0.542829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/aspizu/goboscript</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44020832</td>\n",
       "      <td>0.114064</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://techcrunch.com/2025/05/12/inventwood-i...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44012283</td>\n",
       "      <td>0.534651</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.neowin.net/news/this-printer-compa...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43995067</td>\n",
       "      <td>0.873323</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://phys.org/news/2025-05-reveals-stronges...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44027379</td>\n",
       "      <td>0.322102</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.awanderingmind.blog/posts/2025-05-...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>43971944</td>\n",
       "      <td>0.748661</td>\n",
       "      <td>266.0</td>\n",
       "      <td>30 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://arstechnica.com/space/2025/05/tuesday-...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>44010705</td>\n",
       "      <td>0.184925</td>\n",
       "      <td>267.0</td>\n",
       "      <td>113 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://cacm.acm.org/news/the-collapse-of-gpt/</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>43995005</td>\n",
       "      <td>0.130785</td>\n",
       "      <td>268.0</td>\n",
       "      <td>260 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://eoinmurray.info/boltzmann-machine</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>44016265</td>\n",
       "      <td>0.486395</td>\n",
       "      <td>269.0</td>\n",
       "      <td>45 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://blog.racket-lang.org/2025/05/racket-v8...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>43997728</td>\n",
       "      <td>0.107636</td>\n",
       "      <td>270.0</td>\n",
       "      <td>71 points</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.construction-physics.com/p/fixing-...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id load_time   rank      points title  \\\n",
       "0    44026799  0.542829    1.0   78 points   NaN   \n",
       "1    44020832  0.114064    2.0   83 points   NaN   \n",
       "2    44012283  0.534651    3.0   66 points   NaN   \n",
       "3    43995067  0.873323    4.0  171 points   NaN   \n",
       "4    44027379  0.322102    5.0   12 points   NaN   \n",
       "..        ...       ...    ...         ...   ...   \n",
       "715  43971944  0.748661  266.0   30 points   NaN   \n",
       "716  44010705  0.184925  267.0  113 points   NaN   \n",
       "717  43995005  0.130785  268.0  260 points   NaN   \n",
       "718  44016265  0.486395  269.0   45 points   NaN   \n",
       "719  43997728  0.107636  270.0   71 points   NaN   \n",
       "\n",
       "                                                   url  comment  \n",
       "0                 https://github.com/aspizu/goboscript       22  \n",
       "1    https://techcrunch.com/2025/05/12/inventwood-i...       69  \n",
       "2    https://www.neowin.net/news/this-printer-compa...       25  \n",
       "3    https://phys.org/news/2025-05-reveals-stronges...       83  \n",
       "4    https://www.awanderingmind.blog/posts/2025-05-...        8  \n",
       "..                                                 ...      ...  \n",
       "715  https://arstechnica.com/space/2025/05/tuesday-...       15  \n",
       "716     https://cacm.acm.org/news/the-collapse-of-gpt/      143  \n",
       "717          https://eoinmurray.info/boltzmann-machine       47  \n",
       "718  https://blog.racket-lang.org/2025/05/racket-v8...        3  \n",
       "719  https://www.construction-physics.com/p/fixing-...      129  \n",
       "\n",
       "[720 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "articles_data = pd.read_csv(\n",
    "    './parse/articles_info.csv',\n",
    "    names=[\"id\", \"load_time\", \"rank\", \"points\", \"title\", \"url\", 'comment'],\n",
    "    encoding='cp1252'\n",
    ")\n",
    "\n",
    "articles_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
