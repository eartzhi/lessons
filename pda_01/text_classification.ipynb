{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Классификация текста\n",
        "\n",
        "Одной из широко используемых задач NLP в различных бизнес-задачах является “классификация текста”. Цель классификации текста состоит в том, чтобы автоматически классифицировать текстовые документы по одной или нескольким определенным категориям. Некоторые примеры классификации текста:\n",
        "- Определенеие настроений аудитории из социальных сетей\n",
        "- Обнаружение спама и нежелательных писем\n",
        "- Автоматическая маркировка запросов клиентов\n",
        "- Категоризация новостных статей по определенным темам\n",
        "\n",
        "Классификация текста является примером задачи машинного обучения с учителем, поскольку для обучения классификатора используется помеченный набор данных, содержащий текстовые документы и их метки. Пайплайн классификации текста состоит из 4 основных частей:\n",
        "1. Подготовка данных\n",
        "2. Генерация признаков\n",
        "3. Тренировка модели\n",
        "4. Оценка и тьюнинг модели\n",
        "\n",
        "Проделаем данные шаги."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
        "data = pd.read_excel(\"отзывы за лето.xls\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Предобработка текста\n",
        "\n",
        "Сделаем некоторую базовую предобработку текста"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "from stop_words import get_stop_words\n",
        "from string import punctuation\n",
        "\n",
        "exclude = set(punctuation)\n",
        "sw = set(get_stop_words(\"ru\"))\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"не\\s\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in exclude]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "data['text'] = data['Content'].apply(preprocess_text)\n",
        "data = data[data['Rating'] != 3]\n",
        "data['target'] = data['Rating'] > 3"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(data['text'], data['target'])\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer().fit(train_x.values)\n",
        "\n",
        "xtrain_count = count_vect.transform(train_x)\n",
        "xvalid_count = count_vect.transform(valid_x)\n",
        "\n",
        "tfidf_vec = TfidfVectorizer().fit(train_x.values)\n",
        "xtrain_tfidf = tfidf_vec.transform(train_x)\n",
        "xvalid_tfidf = tfidf_vec.transform(valid_x)\n",
        "\n",
        "tfidf_vec_ngrams = TfidfVectorizer(ngram_range=(1, 3)).fit(train_x.values)\n",
        "xtrain_tfidf_ngram = tfidf_vec.transform(train_x)\n",
        "xvalid_tfidf_ngram = tfidf_vec.transform(valid_x)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Построение моделей\n",
        "\n",
        "Последний шаг в процессе классификации текста - это обучение классификатора с использованием признаков, созданных на предыдущем шаге. Опробуем несколько вариантов моделей машинного обучения."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Naive Bayes\n",
        "\n",
        "Наивный Байес - это метод классификации, основанный на теореме Байеса с допущением независимости между предикторами. Наивный байесовский классификатор предполагает, что наличие определенного признака в классе не связано с наличием какого-либо другого признака в нем."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import naive_bayes, linear_model, ensemble, metrics, svm"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes на Count Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"NB, Count Vectors: \", accuracy)\n",
        "\n",
        "# Naive Bayes на Word Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Naive Bayes на Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"NB, N-Gram Vectors: \", accuracy)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NB, Count Vectors:  0.9195867935993518\n",
            "NB, WordLevel TF-IDF:  0.9041928296536358\n",
            "NB, N-Gram Vectors:  0.9041928296536358\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        " ##### Linear Classifier (Логистическая регрессия)\n",
        " \n",
        "Логистическая регрессия измеряет связь между категориальной зависимой переменной и одной или несколькими независимыми переменными путем оценки вероятностей, используя логистическую/сигмоидную функцию. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Classifier на Count Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"LR, Count Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier на Word Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Linear Classifier на Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"LR, N-Gram Vectors: \", accuracy)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/kinetik/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR, Count Vectors:  0.9088515292687868\n",
            "LR, WordLevel TF-IDF:  0.9171561677131862\n",
            "LR, N-Gram Vectors:  0.9171561677131862\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### SVM\n",
        "\n",
        "SVM -  алгоритм машинного обучения с учителем, который может быть использован как для классификации, так и для регрессии. Модель извлекает наилучшую возможную гиперплоскость/линию, которая разделяет эти два класса."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM на Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"SVM, N-Gram Vectors: \", accuracy)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/kinetik/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM, N-Gram Vectors:  0.8365404091553575\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### RandomForest\n",
        "\n",
        "Cлучайный лес - ансамбль решающих деревьев."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm_notebook"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "[]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 26,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "clf = ensemble.RandomForestClassifier(n_estimators=10000).fit(xtrain_count, train_y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "acs = []\n",
        "for i in tqdm_notebook([10, 30, 60, 100, 1000, 2000]):\n",
        "    clf = ensemble.RandomForestClassifier(n_estimators=i).fit(xtrain_count, train_y)\n",
        "    acs.append(metrics.accuracy_score(clf.predict(xvalid_count), valid_y))\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# RF на Count Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"RF, Count Vectors: \", accuracy)\n",
        "\n",
        "# RF на Word Level TF IDF Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print(\"RF, WordLevel TF-IDF: \", accuracy)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Boosting Model\n",
        "\n",
        "Бустинг - процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Extereme Gradient Boosting на Count Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
        "print(\"Xgb, Count Vectors: \", accuracy)\n",
        "\n",
        "# Extereme Gradient Boosting на Word Level TF IDF Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
        "print(\"Xgb, WordLevel TF-IDF: \", accuracy)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}