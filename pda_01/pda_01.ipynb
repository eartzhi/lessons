{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03caf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(\n",
    "    [\"Разруха не в клозетах, а в головах. \",\n",
    "     \"Люди как люди. Любят деньги, но ведь это всегда было.\",\n",
    "     \"Там хорошо, где нас нет: в прошлом нас уже нет, и оно кажется прекрасным.\",\n",
    "     \"Нет силы более могучей, чем знание; человек, вооружённый знанием, — непобедим.\"\n",
    "     ],\n",
    "    dtype=\"string\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c7b2bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Разруха не в клозетах, а в головах. \n",
       "1    Люди как люди. Любят деньги, но ведь это всегд...\n",
       "2    Там хорошо, где нас нет: в прошлом нас уже нет...\n",
       "3    Нет силы более могучей, чем знание; человек, в...\n",
       "dtype: string"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c98578e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          [РАЗРУХА, НЕ, В, КЛОЗЕТАХ, А, В, ГОЛОВАХ, ]\n",
      "1    [ЛЮДИ, КАК, ЛЮДИ, ЛЮБЯТ, ДЕНЬГИ, НО, ВЕДЬ, ЭТО...\n",
      "2    [ТАМ, ХОРОШО, ГДЕ, НАС, НЕТ, В, ПРОШЛОМ, НАС, ...\n",
      "3    [НЕТ, СИЛЫ, БОЛЕЕ, МОГУЧЕЙ, ЧЕМ, ЗНАНИЕ, ЧЕЛОВ...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Создаем множество из символов пунктуации\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "# Заменяем символы пунктуации на пустые строки\n",
    "s = s.str.replace(f'[{string.punctuation}]', '', regex=True)\n",
    "# Приводим тексты к нижнему регистру\n",
    "s = s.str.upper()\n",
    "# Разделяем тексты по пробелу\n",
    "s = s.str.split(' ')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b12e4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpymorphy2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m----> 6\u001b[0m morpher \u001b[38;5;241m=\u001b[39m \u001b[43mpymorphy2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMorphAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrussian\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m sw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stop_words)\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_type_orig \u001b[38;5;241m=\u001b[39m result_type\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[1;34m(self, units_unbound)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m item[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 235\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43munit\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_unit(item[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[1;34m(self, unit)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_bound_unit\u001b[39m(\u001b[38;5;28mself\u001b[39m, unit):\n\u001b[1;32m--> 246\u001b[0m     unit \u001b[38;5;241m=\u001b[39m \u001b[43munit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m     unit\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unit\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m---> 76\u001b[0m         (key, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_param_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[1;32m---> 70\u001b[0m args, varargs, kw, default \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetargspec\u001b[49m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(args[\u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "morpher = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "sw = set(stop_words)\n",
    "\n",
    "def preprocess_txt(line):\n",
    "    # Почистим строку от пунктуации. Для этого пробежимся по каждому символу и проверим, не является ли он знаком пунктуации\n",
    "    exclude = set(string.punctuation)\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    # Лемматизируем все слова в нашем тексте\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "849c1335",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[0;32m      2\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mРазруха не в клозетах, а в головах. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЛюди как люди. Любят деньги, но ведь это всегда было.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Применяем функцию для предобработки к Series\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(s)\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pandas\\core\\base.py:919\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    916\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m--> 919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\base.py:2322\u001b[0m, in \u001b[0;36mExtensionArray.map\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapper, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;124;03m    Map values using an input mapping or function.\u001b[39;00m\n\u001b[0;32m   2305\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;124;03m        a MultiIndex will be returned.\u001b[39;00m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[0;32m      2\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mРазруха не в клозетах, а в головах. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЛюди как люди. Любят деньги, но ведь это всегда было.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Применяем функцию для предобработки к Series\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mpreprocess_txt\u001b[49m(x))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(s)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_txt' is not defined"
     ]
    }
   ],
   "source": [
    "s = pd.Series(\n",
    "    [\"Разруха не в клозетах, а в головах. \",\n",
    "     \"Люди как люди. Любят деньги, но ведь это всегда было.\",\n",
    "     \"Там хорошо, где нас нет: в прошлом нас уже нет, и оно кажется прекрасным.\",\n",
    "     \"Нет силы более могучей, чем знание; человек, вооружённый знанием, — непобедим.\"\n",
    "     ],\n",
    "    dtype=\"string\"\n",
    ")\n",
    "\n",
    "# Применяем функцию для предобработки к Series\n",
    "s = s.apply(lambda x: preprocess_txt(x))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3455441",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62e420f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awesome</th>\n",
       "      <th>funny</th>\n",
       "      <th>hate</th>\n",
       "      <th>it</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>movie</th>\n",
       "      <th>nice</th>\n",
       "      <th>one</th>\n",
       "      <th>this</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   awesome  funny  hate  it  like  love  movie  nice  one  this  was\n",
       "0        0      1     0   1     1     0      1     0    0     1    0\n",
       "1        0      0     1   0     0     0      1     0    0     1    0\n",
       "2        1      0     0   1     1     0      0     0    0     1    1\n",
       "3        0      0     0   1     0     1      0     1    1     0    0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Создаем the Bag-of-Words модель\n",
    "bag_of_words = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Отобразим Bag-of-Words модель как DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe602fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "text = \"I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.\"\n",
    "tokenized = text.split()\n",
    "bigrams = ngrams(tokenized, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d8ac2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awesome</th>\n",
       "      <th>funny</th>\n",
       "      <th>hate</th>\n",
       "      <th>it</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>movie</th>\n",
       "      <th>nice</th>\n",
       "      <th>one</th>\n",
       "      <th>this</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365003</td>\n",
       "      <td>0.450852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344321</td>\n",
       "      <td>0.425305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344321</td>\n",
       "      <td>0.539445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.541736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    awesome     funny      hate        it      like      love     movie  \\\n",
       "0  0.000000  0.571848  0.000000  0.365003  0.450852  0.000000  0.450852   \n",
       "1  0.000000  0.000000  0.702035  0.000000  0.000000  0.000000  0.553492   \n",
       "2  0.539445  0.000000  0.000000  0.344321  0.425305  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.345783  0.000000  0.541736  0.000000   \n",
       "\n",
       "       nice       one      this       was  \n",
       "0  0.000000  0.000000  0.365003  0.000000  \n",
       "1  0.000000  0.000000  0.448100  0.000000  \n",
       "2  0.000000  0.000000  0.344321  0.539445  \n",
       "3  0.541736  0.541736  0.000000  0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "document = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "values = tfidf_vectorizer.fit_transform(document)\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "pd.DataFrame(values.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac4b29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x16 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "document = [\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n",
    "vectorizer = HashingVectorizer(n_features=2**4)\n",
    "values = vectorizer.fit_transform(document)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db4a598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
      "cereal\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")  # загрузим предтренированные вектора слов из gensim-data\n",
    "# выведем слово наиболее близкое к 'woman', 'king' и далекое от 'man'\n",
    "result = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "print(word_vectors.doesnt_match(\"breakfast cereal dinner lunch\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f0a421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698540687561035),\n",
       " ('monarch', 0.6843381524085999),\n",
       " ('throne', 0.6755736470222473),\n",
       " ('daughter', 0.6594556570053101),\n",
       " ('princess', 0.6520534157752991),\n",
       " ('prince', 0.6517034769058228),\n",
       " ('elizabeth', 0.6464517712593079),\n",
       " ('mother', 0.631171703338623),\n",
       " ('emperor', 0.6106470823287964),\n",
       " ('wife', 0.6098655462265015)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea168339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323495\n"
     ]
    }
   ],
   "source": [
    "similarity = word_vectors.similarity('woman', 'man')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3174e924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>Продам шапки,кажда 200р.Розовая и белая проданны.</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>Темно-синяя, 42 размер,состояние отличное,как ...</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35543</th>\n",
       "      <td>Юбка</td>\n",
       "      <td>Юбка Белая по.Турция фирма adL</td>\n",
       "      <td>5b5f181c62e1c6616a7f6472</td>\n",
       "      <td>9.0</td>\n",
       "      <td>904</td>\n",
       "      <td>{'zhenskaya_odezhda_platya_yubki_tip': 'Юбки',...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35544</th>\n",
       "      <td>Новый твидовый пиджак</td>\n",
       "      <td>Новый с бирками пиджак размер S в стиле Coco C...</td>\n",
       "      <td>5bd6c8b29e94ba033d31f8d0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>908</td>\n",
       "      <td>{'brand_zhenskii': 'Chanel', 'zhenskaya_odezhd...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35545</th>\n",
       "      <td>Женская зимняя куртка</td>\n",
       "      <td>Женская зимняя спортивная куртка фирмы Rossiqn...</td>\n",
       "      <td>5bd6c8bc074b3e1c056f69b2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>903</td>\n",
       "      <td>{'zhenskaya_odezhda_razmer': '48-50 (XL)', 'zh...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35546</th>\n",
       "      <td>Новая золотая ветровка</td>\n",
       "      <td>Женская ветровка размер 44-46. Цвет приглушённ...</td>\n",
       "      <td>5bd6c8fb2138bbc55745362c</td>\n",
       "      <td>9.0</td>\n",
       "      <td>903</td>\n",
       "      <td>{'zhenskaya_odezhda_razmer': '44-46 (М)', 'zhe...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35547</th>\n",
       "      <td>Шарф</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5bd6c8fbaaab283b79142a1f</td>\n",
       "      <td>9.0</td>\n",
       "      <td>914</td>\n",
       "      <td>{'zhenskaya_odezhda_aksessuary_tip': 'Шарфы и ...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35548 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  \\\n",
       "0           Юбка детская ORBY   \n",
       "1                   Ботильоны   \n",
       "2                       Брюки   \n",
       "3        Продам детские шапки   \n",
       "4                      Блузка   \n",
       "...                       ...   \n",
       "35543                    Юбка   \n",
       "35544   Новый твидовый пиджак   \n",
       "35545   Женская зимняя куртка   \n",
       "35546  Новая золотая ветровка   \n",
       "35547                    Шарф   \n",
       "\n",
       "                                            descrirption  \\\n",
       "0      Новая, не носили ни разу. В реале красивей чем...   \n",
       "1      Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "2      Размер 40-42. Брюки почти новые - не знаю как ...   \n",
       "3      Продам шапки,кажда 200р.Розовая и белая проданны.   \n",
       "4      Темно-синяя, 42 размер,состояние отличное,как ...   \n",
       "...                                                  ...   \n",
       "35543                     Юбка Белая по.Турция фирма adL   \n",
       "35544  Новый с бирками пиджак размер S в стиле Coco C...   \n",
       "35545  Женская зимняя спортивная куртка фирмы Rossiqn...   \n",
       "35546  Женская ветровка размер 44-46. Цвет приглушённ...   \n",
       "35547                                                NaN   \n",
       "\n",
       "                     product_id  category_id subcategory_id  \\\n",
       "0      58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1      5667531b2b7f8d127d838c34          9.0            902   \n",
       "2      59534826aaab284cba337e06          9.0            906   \n",
       "3      57de544096ad842e26de8027         22.0           2217   \n",
       "4      5ad4d2626c86cb168d212022          9.0            907   \n",
       "...                         ...          ...            ...   \n",
       "35543  5b5f181c62e1c6616a7f6472          9.0            904   \n",
       "35544  5bd6c8b29e94ba033d31f8d0          9.0            908   \n",
       "35545  5bd6c8bc074b3e1c056f69b2          9.0            903   \n",
       "35546  5bd6c8fb2138bbc55745362c          9.0            903   \n",
       "35547  5bd6c8fbaaab283b79142a1f          9.0            914   \n",
       "\n",
       "                                              properties  \\\n",
       "0            {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1      {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2      {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3      {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4      {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "...                                                  ...   \n",
       "35543  {'zhenskaya_odezhda_platya_yubki_tip': 'Юбки',...   \n",
       "35544  {'brand_zhenskii': 'Chanel', 'zhenskaya_odezhd...   \n",
       "35545  {'zhenskaya_odezhda_razmer': '48-50 (XL)', 'zh...   \n",
       "35546  {'zhenskaya_odezhda_razmer': '44-46 (М)', 'zhe...   \n",
       "35547  {'zhenskaya_odezhda_aksessuary_tip': 'Шарфы и ...   \n",
       "\n",
       "                                             image_links  \n",
       "0      http://cache3.youla.io/files/images/360_360/58...  \n",
       "1      http://cache3.youla.io/files/images/360_360/5b...  \n",
       "2      http://cache3.youla.io/files/images/360_360/59...  \n",
       "3      http://cache3.youla.io/files/images/360_360/57...  \n",
       "4      http://cache3.youla.io/files/images/360_360/5a...  \n",
       "...                                                  ...  \n",
       "35543  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35544  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35545  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35546  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "35547  http://cache3.youla.io/files/images/360_360/5b...  \n",
       "\n",
       "[35548 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "products = pd.read_csv('data/ProductsDataset.csv')\n",
    "display(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de639785",
   "metadata": {},
   "source": [
    "Размечаем вопросы для обучения классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "questiions = pd.DataFrame(questiion, columns='question')\n",
    "questiions['label'] = questiions['question']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
