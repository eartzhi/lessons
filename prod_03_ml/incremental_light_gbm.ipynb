{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорт всех нужных библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание датасета:** Страховые компании берут на себя риски клиентов. Управление рисками является очень важным аспектом страховой отрасли. Страховщики учитывают каждый поддающийся количественной оценке фактор для разработки профилей высоких и низких страховых рисков. Страховщики собирают огромное количество информации о страхователях и анализируют данные. В этом проекте нужно будет проанализировать имеющиеся данные и предсказать, применять ли санкции к страхованию или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/dataset_ml_28.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Agency Type</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Distribution Channel</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45341</td>\n",
       "      <td>28</td>\n",
       "      <td>C2B</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>28.13</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>Online</td>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>112.5</td>\n",
       "      <td>Silver Plan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12958</td>\n",
       "      <td>37</td>\n",
       "      <td>JZI</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>12.95</td>\n",
       "      <td>PHILIPPINES</td>\n",
       "      <td>Online</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Basic Plan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18233</td>\n",
       "      <td>27</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>0.00</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>Online</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31742</td>\n",
       "      <td>36</td>\n",
       "      <td>EPX</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>0.00</td>\n",
       "      <td>SAUDI ARABIA</td>\n",
       "      <td>Online</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Cancellation Plan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14381</td>\n",
       "      <td>26</td>\n",
       "      <td>CWT</td>\n",
       "      <td>Travel Agency</td>\n",
       "      <td>23.76</td>\n",
       "      <td>THAILAND</td>\n",
       "      <td>Online</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.6</td>\n",
       "      <td>Rental Vehicle Excess Insurance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Age Agency    Agency Type  Commision (in value)    Destination  \\\n",
       "0  45341   28    C2B       Airlines                 28.13      SINGAPORE   \n",
       "1  12958   37    JZI       Airlines                 12.95    PHILIPPINES   \n",
       "2  18233   27    EPX  Travel Agency                  0.00  UNITED STATES   \n",
       "3  31742   36    EPX  Travel Agency                  0.00   SAUDI ARABIA   \n",
       "4  14381   26    CWT  Travel Agency                 23.76       THAILAND   \n",
       "\n",
       "  Distribution Channel  Duration Gender  Net Sales  \\\n",
       "0               Online        34      F      112.5   \n",
       "1               Online        53      F       37.0   \n",
       "2               Online        28    NaN       13.0   \n",
       "3               Online         1    NaN       34.0   \n",
       "4               Online        33    NaN       39.6   \n",
       "\n",
       "                      Product Name  Claim  \n",
       "0                      Silver Plan      1  \n",
       "1                       Basic Plan      0  \n",
       "2                Cancellation Plan      0  \n",
       "3                Cancellation Plan      0  \n",
       "4  Rental Vehicle Excess Insurance      0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62288 entries, 0 to 62287\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ID                    62288 non-null  int64  \n",
      " 1   Age                   62288 non-null  int64  \n",
      " 2   Agency                62288 non-null  object \n",
      " 3   Agency Type           62288 non-null  object \n",
      " 4   Commision (in value)  62288 non-null  float64\n",
      " 5   Destination           62288 non-null  object \n",
      " 6   Distribution Channel  62288 non-null  object \n",
      " 7   Duration              62288 non-null  int64  \n",
      " 8   Gender                22713 non-null  object \n",
      " 9   Net Sales             62288 non-null  float64\n",
      " 10  Product Name          62288 non-null  object \n",
      " 11  Claim                 62288 non-null  int64  \n",
      "dtypes: float64(2), int64(4), object(6)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Claim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62288.000000</td>\n",
       "      <td>62288.000000</td>\n",
       "      <td>62288.000000</td>\n",
       "      <td>62288.000000</td>\n",
       "      <td>62288.000000</td>\n",
       "      <td>62288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32844.953458</td>\n",
       "      <td>39.666324</td>\n",
       "      <td>12.829703</td>\n",
       "      <td>60.958804</td>\n",
       "      <td>50.717064</td>\n",
       "      <td>0.200006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18065.417216</td>\n",
       "      <td>14.014652</td>\n",
       "      <td>23.498745</td>\n",
       "      <td>114.325330</td>\n",
       "      <td>63.166715</td>\n",
       "      <td>0.400008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-389.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17579.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33446.500000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48532.250000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>14.440000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63323.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>262.760000</td>\n",
       "      <td>4881.000000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID           Age  Commision (in value)      Duration  \\\n",
       "count  62288.000000  62288.000000          62288.000000  62288.000000   \n",
       "mean   32844.953458     39.666324             12.829703     60.958804   \n",
       "std    18065.417216     14.014652             23.498745    114.325330   \n",
       "min        0.000000      0.000000              0.000000     -2.000000   \n",
       "25%    17579.000000     33.000000              0.000000     10.000000   \n",
       "50%    33446.500000     36.000000              1.880000     25.000000   \n",
       "75%    48532.250000     43.000000             14.440000     59.000000   \n",
       "max    63323.000000    118.000000            262.760000   4881.000000   \n",
       "\n",
       "          Net Sales         Claim  \n",
       "count  62288.000000  62288.000000  \n",
       "mean      50.717064      0.200006  \n",
       "std       63.166715      0.400008  \n",
       "min     -389.000000      0.000000  \n",
       "25%       20.000000      0.000000  \n",
       "50%       29.700000      0.000000  \n",
       "75%       58.000000      0.000000  \n",
       "max      682.000000      1.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** В колонке Duration минимальное значние \"-2\", так как продолжительность поездки не может быть меньше 0. Такие данные надо выбросить. Но и максимаьлная продолжительность в 4881 дней, кажется очень большой. Давайте установим максимальное значение \"Duration\" в 1000 дней.\n",
    "\n",
    "**2.** Также добавим колонку категориальный признак: сгруппируем клиентов по возрасту (\"ребенок\", \"взрослый\", \"пожилового возраста\"). \n",
    "\n",
    "**3.** В колонке пола есть очень много пропусков, который практически никак не заполнить. Поэтому удалим ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_convert(age):\n",
    "    result = ''\n",
    "    if(age <= 21):\n",
    "        result = 'Child'\n",
    "    elif(age <= 60):\n",
    "        result = 'Adult'\n",
    "    else:\n",
    "        result = 'Senior'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_processing(df):\n",
    "    \n",
    "    df['Age Group'] = df['Age'].map(lambda x: age_convert(x))\n",
    "\n",
    "    df.drop('Gender',axis=1, inplace=True)\n",
    "    \n",
    "    df.loc[df.Duration < 0, 'Duration'] = df['Duration'].median()\n",
    "\n",
    "    df.loc[df.Duration > 1000, 'Duration'] = 1000\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['Agency', 'Agency Type', 'Destination', 'Distribution Channel', 'Product Name', 'Age Group'], drop_first=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_pre_processing(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Commision (in value)</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Net Sales</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Agency_ART</th>\n",
       "      <th>Agency_C2B</th>\n",
       "      <th>Agency_CBH</th>\n",
       "      <th>Agency_CCR</th>\n",
       "      <th>...</th>\n",
       "      <th>Product Name_Silver Plan</th>\n",
       "      <th>Product Name_Single Trip Travel Protect Gold</th>\n",
       "      <th>Product Name_Single Trip Travel Protect Platinum</th>\n",
       "      <th>Product Name_Single Trip Travel Protect Silver</th>\n",
       "      <th>Product Name_Spouse or Parents Comprehensive Plan</th>\n",
       "      <th>Product Name_Ticket Protector</th>\n",
       "      <th>Product Name_Travel Cruise Protect</th>\n",
       "      <th>Product Name_Value Plan</th>\n",
       "      <th>Age Group_Child</th>\n",
       "      <th>Age Group_Senior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45341</td>\n",
       "      <td>28</td>\n",
       "      <td>28.13</td>\n",
       "      <td>34</td>\n",
       "      <td>112.5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12958</td>\n",
       "      <td>37</td>\n",
       "      <td>12.95</td>\n",
       "      <td>53</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18233</td>\n",
       "      <td>27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31742</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14381</td>\n",
       "      <td>26</td>\n",
       "      <td>23.76</td>\n",
       "      <td>33</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Age  Commision (in value)  Duration  Net Sales  Claim  Agency_ART  \\\n",
       "0  45341   28                 28.13        34      112.5      1       False   \n",
       "1  12958   37                 12.95        53       37.0      0       False   \n",
       "2  18233   27                  0.00        28       13.0      0       False   \n",
       "3  31742   36                  0.00         1       34.0      0       False   \n",
       "4  14381   26                 23.76        33       39.6      0       False   \n",
       "\n",
       "   Agency_C2B  Agency_CBH  Agency_CCR  ...  Product Name_Silver Plan  \\\n",
       "0        True       False       False  ...                      True   \n",
       "1       False       False       False  ...                     False   \n",
       "2       False       False       False  ...                     False   \n",
       "3       False       False       False  ...                     False   \n",
       "4       False       False       False  ...                     False   \n",
       "\n",
       "   Product Name_Single Trip Travel Protect Gold  \\\n",
       "0                                         False   \n",
       "1                                         False   \n",
       "2                                         False   \n",
       "3                                         False   \n",
       "4                                         False   \n",
       "\n",
       "   Product Name_Single Trip Travel Protect Platinum  \\\n",
       "0                                             False   \n",
       "1                                             False   \n",
       "2                                             False   \n",
       "3                                             False   \n",
       "4                                             False   \n",
       "\n",
       "   Product Name_Single Trip Travel Protect Silver  \\\n",
       "0                                           False   \n",
       "1                                           False   \n",
       "2                                           False   \n",
       "3                                           False   \n",
       "4                                           False   \n",
       "\n",
       "   Product Name_Spouse or Parents Comprehensive Plan  \\\n",
       "0                                              False   \n",
       "1                                              False   \n",
       "2                                              False   \n",
       "3                                              False   \n",
       "4                                              False   \n",
       "\n",
       "   Product Name_Ticket Protector  Product Name_Travel Cruise Protect  \\\n",
       "0                          False                               False   \n",
       "1                          False                               False   \n",
       "2                          False                               False   \n",
       "3                          False                               False   \n",
       "4                          False                               False   \n",
       "\n",
       "   Product Name_Value Plan  Age Group_Child  Age Group_Senior  \n",
       "0                    False            False             False  \n",
       "1                    False            False             False  \n",
       "2                    False            False             False  \n",
       "3                    False            False             False  \n",
       "4                    False            False             False  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('Claim', axis = 1)\n",
    "y = dataset['Claim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация стримингового прочтения файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем воссоздать потом реальных данных. Для этого разобьем данные на батчи и будем их по порядку считывать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_reading(X_train, y_train, batch_size=5000):\n",
    "    X = []\n",
    "    y = []\n",
    "    current_line = 0\n",
    "    train_data, train_label = shuffle(X_train, y_train, random_state=0)\n",
    "    train_data = train_data.to_numpy()\n",
    "    for row, target in zip(train_data, train_label):\n",
    "        X.append(row)\n",
    "        y.append(target)\n",
    "\n",
    "        current_line += 1\n",
    "        if current_line >= batch_size:\n",
    "            X, y = np.array(X), np.array(y)\n",
    "            yield X, y\n",
    "            X, y = [], []\n",
    "            current_line = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IncrementaLightGbm(X, y):  \n",
    "    gbm = None\n",
    "\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'application': 'binary',  \n",
    "        'boosting_type': 'gbdt', \n",
    "        'learning_rate': 0.05,  \n",
    "        'tree_learner': 'serial',\n",
    "        'metric': ['binary_logloss', 'auc'], \n",
    "        'max_bin': 255,\n",
    "    }\n",
    "    streaming_train_iterators = streaming_reading(X, y, batch_size=5000)\n",
    "\n",
    "    for i, data in enumerate(streaming_train_iterators):\n",
    "        X_batch = data[0]\n",
    "        y_batch = data[1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_batch, y_batch, test_size=0.1, random_state=0)\n",
    "        y_train = y_train.ravel()\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=1000,\n",
    "                        valid_sets=lgb_eval,\n",
    "                        init_model=gbm, \n",
    "                        # early_stopping_rounds=10,\n",
    "                        # verbose_eval=False,\n",
    "                        keep_training_booster=True, \n",
    "                        # callbacks=[lgb.early_stopping(stopping_rounds=10)]\n",
    "                        callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(True)])  \n",
    "\n",
    "        print(\"{} time\".format(i))  \n",
    "        score_train = dict([(score[1], score[2]) for score in gbm.eval_train()])\n",
    "        print('The score of the current model in the training set is: logloss=%.4f, auc=%.4f, \\n'\n",
    "              % (score_train['binary_logloss'], score_train['auc']))\n",
    "\n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 863, number of negative: 3637\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1076\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 60\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.191778 -> initscore=-1.438500\n",
      "[LightGBM] [Info] Start training from score -1.438500\n",
      "[1]\tvalid_0's binary_logloss: 0.487344\tvalid_0's auc: 0.821562\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.475352\tvalid_0's auc: 0.825175\n",
      "[3]\tvalid_0's binary_logloss: 0.46522\tvalid_0's auc: 0.827325\n",
      "[4]\tvalid_0's binary_logloss: 0.456158\tvalid_0's auc: 0.832175\n",
      "[5]\tvalid_0's binary_logloss: 0.447811\tvalid_0's auc: 0.834225\n",
      "[6]\tvalid_0's binary_logloss: 0.440599\tvalid_0's auc: 0.833762\n",
      "[7]\tvalid_0's binary_logloss: 0.433123\tvalid_0's auc: 0.841838\n",
      "[8]\tvalid_0's binary_logloss: 0.426747\tvalid_0's auc: 0.8421\n",
      "[9]\tvalid_0's binary_logloss: 0.421107\tvalid_0's auc: 0.844812\n",
      "[10]\tvalid_0's binary_logloss: 0.415911\tvalid_0's auc: 0.8447\n",
      "[11]\tvalid_0's binary_logloss: 0.412135\tvalid_0's auc: 0.847675\n",
      "[12]\tvalid_0's binary_logloss: 0.407138\tvalid_0's auc: 0.8485\n",
      "[13]\tvalid_0's binary_logloss: 0.403063\tvalid_0's auc: 0.850475\n",
      "[14]\tvalid_0's binary_logloss: 0.398959\tvalid_0's auc: 0.85215\n",
      "[15]\tvalid_0's binary_logloss: 0.39546\tvalid_0's auc: 0.852712\n",
      "[16]\tvalid_0's binary_logloss: 0.392831\tvalid_0's auc: 0.852688\n",
      "[17]\tvalid_0's binary_logloss: 0.38994\tvalid_0's auc: 0.853237\n",
      "[18]\tvalid_0's binary_logloss: 0.386946\tvalid_0's auc: 0.853563\n",
      "[19]\tvalid_0's binary_logloss: 0.384138\tvalid_0's auc: 0.854025\n",
      "[20]\tvalid_0's binary_logloss: 0.381525\tvalid_0's auc: 0.854487\n",
      "[21]\tvalid_0's binary_logloss: 0.379525\tvalid_0's auc: 0.855287\n",
      "[22]\tvalid_0's binary_logloss: 0.377708\tvalid_0's auc: 0.855012\n",
      "[23]\tvalid_0's binary_logloss: 0.375906\tvalid_0's auc: 0.854725\n",
      "[24]\tvalid_0's binary_logloss: 0.374869\tvalid_0's auc: 0.853425\n",
      "[25]\tvalid_0's binary_logloss: 0.373217\tvalid_0's auc: 0.853725\n",
      "[26]\tvalid_0's binary_logloss: 0.37155\tvalid_0's auc: 0.854213\n",
      "[27]\tvalid_0's binary_logloss: 0.369723\tvalid_0's auc: 0.858337\n",
      "[28]\tvalid_0's binary_logloss: 0.368773\tvalid_0's auc: 0.857762\n",
      "[29]\tvalid_0's binary_logloss: 0.368061\tvalid_0's auc: 0.857537\n",
      "[30]\tvalid_0's binary_logloss: 0.366646\tvalid_0's auc: 0.858237\n",
      "[31]\tvalid_0's binary_logloss: 0.365431\tvalid_0's auc: 0.858437\n",
      "[32]\tvalid_0's binary_logloss: 0.363814\tvalid_0's auc: 0.859962\n",
      "[33]\tvalid_0's binary_logloss: 0.362887\tvalid_0's auc: 0.860487\n",
      "[34]\tvalid_0's binary_logloss: 0.362214\tvalid_0's auc: 0.860375\n",
      "[35]\tvalid_0's binary_logloss: 0.361708\tvalid_0's auc: 0.860475\n",
      "[36]\tvalid_0's binary_logloss: 0.360163\tvalid_0's auc: 0.861125\n",
      "[37]\tvalid_0's binary_logloss: 0.360257\tvalid_0's auc: 0.8604\n",
      "[38]\tvalid_0's binary_logloss: 0.359473\tvalid_0's auc: 0.860225\n",
      "[39]\tvalid_0's binary_logloss: 0.358488\tvalid_0's auc: 0.86075\n",
      "[40]\tvalid_0's binary_logloss: 0.357511\tvalid_0's auc: 0.861537\n",
      "[41]\tvalid_0's binary_logloss: 0.356741\tvalid_0's auc: 0.862163\n",
      "[42]\tvalid_0's binary_logloss: 0.355721\tvalid_0's auc: 0.862088\n",
      "[43]\tvalid_0's binary_logloss: 0.355817\tvalid_0's auc: 0.861138\n",
      "[44]\tvalid_0's binary_logloss: 0.355894\tvalid_0's auc: 0.860287\n",
      "[45]\tvalid_0's binary_logloss: 0.35577\tvalid_0's auc: 0.860638\n",
      "[46]\tvalid_0's binary_logloss: 0.35506\tvalid_0's auc: 0.861062\n",
      "[47]\tvalid_0's binary_logloss: 0.354989\tvalid_0's auc: 0.860313\n",
      "[48]\tvalid_0's binary_logloss: 0.354063\tvalid_0's auc: 0.861475\n",
      "[49]\tvalid_0's binary_logloss: 0.354621\tvalid_0's auc: 0.860225\n",
      "[50]\tvalid_0's binary_logloss: 0.35386\tvalid_0's auc: 0.860725\n",
      "[51]\tvalid_0's binary_logloss: 0.352748\tvalid_0's auc: 0.861475\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's binary_logloss: 0.356741\tvalid_0's auc: 0.862163\n",
      "0 time\n",
      "The score of the current model in the training set is: logloss=0.2759, auc=0.9338, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 952, number of negative: 3548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 61\n",
      "[52]\tvalid_0's binary_logloss: 0.330687\tvalid_0's auc: 0.88158\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[53]\tvalid_0's binary_logloss: 0.329773\tvalid_0's auc: 0.881799\n",
      "[54]\tvalid_0's binary_logloss: 0.328813\tvalid_0's auc: 0.883426\n",
      "[55]\tvalid_0's binary_logloss: 0.328229\tvalid_0's auc: 0.883936\n",
      "[56]\tvalid_0's binary_logloss: 0.327247\tvalid_0's auc: 0.884785\n",
      "[57]\tvalid_0's binary_logloss: 0.327146\tvalid_0's auc: 0.884421\n",
      "[58]\tvalid_0's binary_logloss: 0.326392\tvalid_0's auc: 0.884688\n",
      "[59]\tvalid_0's binary_logloss: 0.325388\tvalid_0's auc: 0.885684\n",
      "[60]\tvalid_0's binary_logloss: 0.323943\tvalid_0's auc: 0.888039\n",
      "[61]\tvalid_0's binary_logloss: 0.323318\tvalid_0's auc: 0.888452\n",
      "[62]\tvalid_0's binary_logloss: 0.323232\tvalid_0's auc: 0.887918\n",
      "[63]\tvalid_0's binary_logloss: 0.32251\tvalid_0's auc: 0.88833\n",
      "[64]\tvalid_0's binary_logloss: 0.321813\tvalid_0's auc: 0.888719\n",
      "[65]\tvalid_0's binary_logloss: 0.321314\tvalid_0's auc: 0.888913\n",
      "[66]\tvalid_0's binary_logloss: 0.320551\tvalid_0's auc: 0.889375\n",
      "[67]\tvalid_0's binary_logloss: 0.319837\tvalid_0's auc: 0.889812\n",
      "[68]\tvalid_0's binary_logloss: 0.3194\tvalid_0's auc: 0.89037\n",
      "[69]\tvalid_0's binary_logloss: 0.318947\tvalid_0's auc: 0.890467\n",
      "[70]\tvalid_0's binary_logloss: 0.318363\tvalid_0's auc: 0.890831\n",
      "[71]\tvalid_0's binary_logloss: 0.317295\tvalid_0's auc: 0.892021\n",
      "[72]\tvalid_0's binary_logloss: 0.316794\tvalid_0's auc: 0.89241\n",
      "[73]\tvalid_0's binary_logloss: 0.316364\tvalid_0's auc: 0.892822\n",
      "[74]\tvalid_0's binary_logloss: 0.315721\tvalid_0's auc: 0.89326\n",
      "[75]\tvalid_0's binary_logloss: 0.315138\tvalid_0's auc: 0.894304\n",
      "[76]\tvalid_0's binary_logloss: 0.314472\tvalid_0's auc: 0.894862\n",
      "[77]\tvalid_0's binary_logloss: 0.313995\tvalid_0's auc: 0.895858\n",
      "[78]\tvalid_0's binary_logloss: 0.313455\tvalid_0's auc: 0.896076\n",
      "[79]\tvalid_0's binary_logloss: 0.313434\tvalid_0's auc: 0.895906\n",
      "[80]\tvalid_0's binary_logloss: 0.312571\tvalid_0's auc: 0.896513\n",
      "[81]\tvalid_0's binary_logloss: 0.312527\tvalid_0's auc: 0.896537\n",
      "[82]\tvalid_0's binary_logloss: 0.311977\tvalid_0's auc: 0.896489\n",
      "[83]\tvalid_0's binary_logloss: 0.311577\tvalid_0's auc: 0.89644\n",
      "[84]\tvalid_0's binary_logloss: 0.311527\tvalid_0's auc: 0.896805\n",
      "[85]\tvalid_0's binary_logloss: 0.311582\tvalid_0's auc: 0.89627\n",
      "[86]\tvalid_0's binary_logloss: 0.311811\tvalid_0's auc: 0.896586\n",
      "[87]\tvalid_0's binary_logloss: 0.311515\tvalid_0's auc: 0.896732\n",
      "[88]\tvalid_0's binary_logloss: 0.31099\tvalid_0's auc: 0.897145\n",
      "[89]\tvalid_0's binary_logloss: 0.310566\tvalid_0's auc: 0.897412\n",
      "[90]\tvalid_0's binary_logloss: 0.30968\tvalid_0's auc: 0.897849\n",
      "[91]\tvalid_0's binary_logloss: 0.309453\tvalid_0's auc: 0.898237\n",
      "[92]\tvalid_0's binary_logloss: 0.309466\tvalid_0's auc: 0.89831\n",
      "[93]\tvalid_0's binary_logloss: 0.309673\tvalid_0's auc: 0.897703\n",
      "[94]\tvalid_0's binary_logloss: 0.30862\tvalid_0's auc: 0.89916\n",
      "[95]\tvalid_0's binary_logloss: 0.308236\tvalid_0's auc: 0.899087\n",
      "[96]\tvalid_0's binary_logloss: 0.308062\tvalid_0's auc: 0.899451\n",
      "[97]\tvalid_0's binary_logloss: 0.30754\tvalid_0's auc: 0.900083\n",
      "[98]\tvalid_0's binary_logloss: 0.307201\tvalid_0's auc: 0.900398\n",
      "[99]\tvalid_0's binary_logloss: 0.307072\tvalid_0's auc: 0.900374\n",
      "[100]\tvalid_0's binary_logloss: 0.307041\tvalid_0's auc: 0.900204\n",
      "[101]\tvalid_0's binary_logloss: 0.306562\tvalid_0's auc: 0.900544\n",
      "[102]\tvalid_0's binary_logloss: 0.306327\tvalid_0's auc: 0.900617\n",
      "[103]\tvalid_0's binary_logloss: 0.3066\tvalid_0's auc: 0.900228\n",
      "[104]\tvalid_0's binary_logloss: 0.30641\tvalid_0's auc: 0.90035\n",
      "[105]\tvalid_0's binary_logloss: 0.30638\tvalid_0's auc: 0.900325\n",
      "[106]\tvalid_0's binary_logloss: 0.306372\tvalid_0's auc: 0.90035\n",
      "[107]\tvalid_0's binary_logloss: 0.306235\tvalid_0's auc: 0.900447\n",
      "[108]\tvalid_0's binary_logloss: 0.305905\tvalid_0's auc: 0.900568\n",
      "[109]\tvalid_0's binary_logloss: 0.305799\tvalid_0's auc: 0.900325\n",
      "[110]\tvalid_0's binary_logloss: 0.305456\tvalid_0's auc: 0.900908\n",
      "[111]\tvalid_0's binary_logloss: 0.305231\tvalid_0's auc: 0.901005\n",
      "[112]\tvalid_0's binary_logloss: 0.30499\tvalid_0's auc: 0.900665\n",
      "[113]\tvalid_0's binary_logloss: 0.305164\tvalid_0's auc: 0.900495\n",
      "[114]\tvalid_0's binary_logloss: 0.305203\tvalid_0's auc: 0.90052\n",
      "[115]\tvalid_0's binary_logloss: 0.304996\tvalid_0's auc: 0.900471\n",
      "[116]\tvalid_0's binary_logloss: 0.305406\tvalid_0's auc: 0.900447\n",
      "[117]\tvalid_0's binary_logloss: 0.305048\tvalid_0's auc: 0.900617\n",
      "[118]\tvalid_0's binary_logloss: 0.305069\tvalid_0's auc: 0.900204\n",
      "[119]\tvalid_0's binary_logloss: 0.304796\tvalid_0's auc: 0.900398\n",
      "[120]\tvalid_0's binary_logloss: 0.30478\tvalid_0's auc: 0.90052\n",
      "[121]\tvalid_0's binary_logloss: 0.304629\tvalid_0's auc: 0.900738\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.305231\tvalid_0's auc: 0.901005\n",
      "1 time\n",
      "The score of the current model in the training set is: logloss=0.2367, auc=0.9564, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 870, number of negative: 3630\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1099\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 59\n",
      "[122]\tvalid_0's binary_logloss: 0.323256\tvalid_0's auc: 0.888161\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[123]\tvalid_0's binary_logloss: 0.322566\tvalid_0's auc: 0.888211\n",
      "[124]\tvalid_0's binary_logloss: 0.322661\tvalid_0's auc: 0.887814\n",
      "[125]\tvalid_0's binary_logloss: 0.322464\tvalid_0's auc: 0.888012\n",
      "[126]\tvalid_0's binary_logloss: 0.321982\tvalid_0's auc: 0.887962\n",
      "[127]\tvalid_0's binary_logloss: 0.321667\tvalid_0's auc: 0.88831\n",
      "[128]\tvalid_0's binary_logloss: 0.321361\tvalid_0's auc: 0.88836\n",
      "[129]\tvalid_0's binary_logloss: 0.321408\tvalid_0's auc: 0.887863\n",
      "[130]\tvalid_0's binary_logloss: 0.321473\tvalid_0's auc: 0.887962\n",
      "[131]\tvalid_0's binary_logloss: 0.321517\tvalid_0's auc: 0.888062\n",
      "[132]\tvalid_0's binary_logloss: 0.321854\tvalid_0's auc: 0.887615\n",
      "[133]\tvalid_0's binary_logloss: 0.321624\tvalid_0's auc: 0.88764\n",
      "[134]\tvalid_0's binary_logloss: 0.320345\tvalid_0's auc: 0.888434\n",
      "[135]\tvalid_0's binary_logloss: 0.319887\tvalid_0's auc: 0.888781\n",
      "[136]\tvalid_0's binary_logloss: 0.320135\tvalid_0's auc: 0.88826\n",
      "[137]\tvalid_0's binary_logloss: 0.319758\tvalid_0's auc: 0.888781\n",
      "[138]\tvalid_0's binary_logloss: 0.319882\tvalid_0's auc: 0.889129\n",
      "[139]\tvalid_0's binary_logloss: 0.319747\tvalid_0's auc: 0.889278\n",
      "[140]\tvalid_0's binary_logloss: 0.31934\tvalid_0's auc: 0.889873\n",
      "[141]\tvalid_0's binary_logloss: 0.319343\tvalid_0's auc: 0.889948\n",
      "[142]\tvalid_0's binary_logloss: 0.319221\tvalid_0's auc: 0.890295\n",
      "[143]\tvalid_0's binary_logloss: 0.318935\tvalid_0's auc: 0.890394\n",
      "[144]\tvalid_0's binary_logloss: 0.318955\tvalid_0's auc: 0.890692\n",
      "[145]\tvalid_0's binary_logloss: 0.318439\tvalid_0's auc: 0.891015\n",
      "[146]\tvalid_0's binary_logloss: 0.318144\tvalid_0's auc: 0.890866\n",
      "[147]\tvalid_0's binary_logloss: 0.318563\tvalid_0's auc: 0.890791\n",
      "[148]\tvalid_0's binary_logloss: 0.318337\tvalid_0's auc: 0.890618\n",
      "[149]\tvalid_0's binary_logloss: 0.318298\tvalid_0's auc: 0.890618\n",
      "[150]\tvalid_0's binary_logloss: 0.317946\tvalid_0's auc: 0.890915\n",
      "[151]\tvalid_0's binary_logloss: 0.317848\tvalid_0's auc: 0.891585\n",
      "[152]\tvalid_0's binary_logloss: 0.317395\tvalid_0's auc: 0.892255\n",
      "[153]\tvalid_0's binary_logloss: 0.317374\tvalid_0's auc: 0.892206\n",
      "[154]\tvalid_0's binary_logloss: 0.317104\tvalid_0's auc: 0.892603\n",
      "[155]\tvalid_0's binary_logloss: 0.31709\tvalid_0's auc: 0.892479\n",
      "[156]\tvalid_0's binary_logloss: 0.316642\tvalid_0's auc: 0.892776\n",
      "[157]\tvalid_0's binary_logloss: 0.316414\tvalid_0's auc: 0.893049\n",
      "[158]\tvalid_0's binary_logloss: 0.315494\tvalid_0's auc: 0.893322\n",
      "[159]\tvalid_0's binary_logloss: 0.315583\tvalid_0's auc: 0.89367\n",
      "[160]\tvalid_0's binary_logloss: 0.315294\tvalid_0's auc: 0.894042\n",
      "[161]\tvalid_0's binary_logloss: 0.314523\tvalid_0's auc: 0.894662\n",
      "[162]\tvalid_0's binary_logloss: 0.314365\tvalid_0's auc: 0.894911\n",
      "[163]\tvalid_0's binary_logloss: 0.313283\tvalid_0's auc: 0.895655\n",
      "[164]\tvalid_0's binary_logloss: 0.312702\tvalid_0's auc: 0.896002\n",
      "[165]\tvalid_0's binary_logloss: 0.312894\tvalid_0's auc: 0.895506\n",
      "[166]\tvalid_0's binary_logloss: 0.312279\tvalid_0's auc: 0.896424\n",
      "[167]\tvalid_0's binary_logloss: 0.312273\tvalid_0's auc: 0.896325\n",
      "[168]\tvalid_0's binary_logloss: 0.312448\tvalid_0's auc: 0.896226\n",
      "[169]\tvalid_0's binary_logloss: 0.312121\tvalid_0's auc: 0.896201\n",
      "[170]\tvalid_0's binary_logloss: 0.311791\tvalid_0's auc: 0.896722\n",
      "[171]\tvalid_0's binary_logloss: 0.311307\tvalid_0's auc: 0.897169\n",
      "[172]\tvalid_0's binary_logloss: 0.311419\tvalid_0's auc: 0.896896\n",
      "[173]\tvalid_0's binary_logloss: 0.310994\tvalid_0's auc: 0.897665\n",
      "[174]\tvalid_0's binary_logloss: 0.310684\tvalid_0's auc: 0.898037\n",
      "[175]\tvalid_0's binary_logloss: 0.310561\tvalid_0's auc: 0.898012\n",
      "[176]\tvalid_0's binary_logloss: 0.310646\tvalid_0's auc: 0.898112\n",
      "[177]\tvalid_0's binary_logloss: 0.310628\tvalid_0's auc: 0.897863\n",
      "[178]\tvalid_0's binary_logloss: 0.309986\tvalid_0's auc: 0.898608\n",
      "[179]\tvalid_0's binary_logloss: 0.310088\tvalid_0's auc: 0.898434\n",
      "[180]\tvalid_0's binary_logloss: 0.309499\tvalid_0's auc: 0.898906\n",
      "[181]\tvalid_0's binary_logloss: 0.309913\tvalid_0's auc: 0.898583\n",
      "[182]\tvalid_0's binary_logloss: 0.309374\tvalid_0's auc: 0.89903\n",
      "[183]\tvalid_0's binary_logloss: 0.308977\tvalid_0's auc: 0.899476\n",
      "[184]\tvalid_0's binary_logloss: 0.308731\tvalid_0's auc: 0.899998\n",
      "[185]\tvalid_0's binary_logloss: 0.308475\tvalid_0's auc: 0.900122\n",
      "[186]\tvalid_0's binary_logloss: 0.308309\tvalid_0's auc: 0.899973\n",
      "[187]\tvalid_0's binary_logloss: 0.308694\tvalid_0's auc: 0.899551\n",
      "[188]\tvalid_0's binary_logloss: 0.308486\tvalid_0's auc: 0.899725\n",
      "[189]\tvalid_0's binary_logloss: 0.308286\tvalid_0's auc: 0.899948\n",
      "[190]\tvalid_0's binary_logloss: 0.308389\tvalid_0's auc: 0.8997\n",
      "[191]\tvalid_0's binary_logloss: 0.308557\tvalid_0's auc: 0.8997\n",
      "[192]\tvalid_0's binary_logloss: 0.308409\tvalid_0's auc: 0.899849\n",
      "[193]\tvalid_0's binary_logloss: 0.308591\tvalid_0's auc: 0.899675\n",
      "[194]\tvalid_0's binary_logloss: 0.308925\tvalid_0's auc: 0.899452\n",
      "[195]\tvalid_0's binary_logloss: 0.308808\tvalid_0's auc: 0.899501\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's binary_logloss: 0.308475\tvalid_0's auc: 0.900122\n",
      "2 time\n",
      "The score of the current model in the training set is: logloss=0.2046, auc=0.9689, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 972, number of negative: 3528\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1091\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 58\n",
      "[196]\tvalid_0's binary_logloss: 0.283541\tvalid_0's auc: 0.92321\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[197]\tvalid_0's binary_logloss: 0.282158\tvalid_0's auc: 0.92436\n",
      "[198]\tvalid_0's binary_logloss: 0.280928\tvalid_0's auc: 0.924922\n",
      "[199]\tvalid_0's binary_logloss: 0.279806\tvalid_0's auc: 0.925534\n",
      "[200]\tvalid_0's binary_logloss: 0.278676\tvalid_0's auc: 0.926365\n",
      "[201]\tvalid_0's binary_logloss: 0.277522\tvalid_0's auc: 0.926683\n",
      "[202]\tvalid_0's binary_logloss: 0.277333\tvalid_0's auc: 0.927172\n",
      "[203]\tvalid_0's binary_logloss: 0.277056\tvalid_0's auc: 0.92749\n",
      "[204]\tvalid_0's binary_logloss: 0.276329\tvalid_0's auc: 0.928126\n",
      "[205]\tvalid_0's binary_logloss: 0.275609\tvalid_0's auc: 0.928517\n",
      "[206]\tvalid_0's binary_logloss: 0.275674\tvalid_0's auc: 0.928444\n",
      "[207]\tvalid_0's binary_logloss: 0.274531\tvalid_0's auc: 0.929471\n",
      "[208]\tvalid_0's binary_logloss: 0.273829\tvalid_0's auc: 0.929838\n",
      "[209]\tvalid_0's binary_logloss: 0.273666\tvalid_0's auc: 0.929838\n",
      "[210]\tvalid_0's binary_logloss: 0.273257\tvalid_0's auc: 0.929985\n",
      "[211]\tvalid_0's binary_logloss: 0.272558\tvalid_0's auc: 0.930425\n",
      "[212]\tvalid_0's binary_logloss: 0.272151\tvalid_0's auc: 0.930694\n",
      "[213]\tvalid_0's binary_logloss: 0.271983\tvalid_0's auc: 0.931403\n",
      "[214]\tvalid_0's binary_logloss: 0.271851\tvalid_0's auc: 0.931232\n",
      "[215]\tvalid_0's binary_logloss: 0.271566\tvalid_0's auc: 0.931721\n",
      "[216]\tvalid_0's binary_logloss: 0.27145\tvalid_0's auc: 0.931696\n",
      "[217]\tvalid_0's binary_logloss: 0.270837\tvalid_0's auc: 0.932014\n",
      "[218]\tvalid_0's binary_logloss: 0.270478\tvalid_0's auc: 0.932552\n",
      "[219]\tvalid_0's binary_logloss: 0.27033\tvalid_0's auc: 0.932552\n",
      "[220]\tvalid_0's binary_logloss: 0.269944\tvalid_0's auc: 0.932528\n",
      "[221]\tvalid_0's binary_logloss: 0.269099\tvalid_0's auc: 0.933311\n",
      "[222]\tvalid_0's binary_logloss: 0.268543\tvalid_0's auc: 0.933824\n",
      "[223]\tvalid_0's binary_logloss: 0.268239\tvalid_0's auc: 0.933897\n",
      "[224]\tvalid_0's binary_logloss: 0.268232\tvalid_0's auc: 0.933971\n",
      "[225]\tvalid_0's binary_logloss: 0.268176\tvalid_0's auc: 0.933775\n",
      "[226]\tvalid_0's binary_logloss: 0.267853\tvalid_0's auc: 0.934215\n",
      "[227]\tvalid_0's binary_logloss: 0.267681\tvalid_0's auc: 0.933971\n",
      "[228]\tvalid_0's binary_logloss: 0.267204\tvalid_0's auc: 0.934313\n",
      "[229]\tvalid_0's binary_logloss: 0.266719\tvalid_0's auc: 0.9349\n",
      "[230]\tvalid_0's binary_logloss: 0.266888\tvalid_0's auc: 0.934851\n",
      "[231]\tvalid_0's binary_logloss: 0.266321\tvalid_0's auc: 0.935169\n",
      "[232]\tvalid_0's binary_logloss: 0.266053\tvalid_0's auc: 0.935389\n",
      "[233]\tvalid_0's binary_logloss: 0.265751\tvalid_0's auc: 0.935511\n",
      "[234]\tvalid_0's binary_logloss: 0.265466\tvalid_0's auc: 0.935609\n",
      "[235]\tvalid_0's binary_logloss: 0.265106\tvalid_0's auc: 0.935732\n",
      "[236]\tvalid_0's binary_logloss: 0.264686\tvalid_0's auc: 0.936147\n",
      "[237]\tvalid_0's binary_logloss: 0.264657\tvalid_0's auc: 0.936196\n",
      "[238]\tvalid_0's binary_logloss: 0.264227\tvalid_0's auc: 0.936196\n",
      "[239]\tvalid_0's binary_logloss: 0.264241\tvalid_0's auc: 0.936343\n",
      "[240]\tvalid_0's binary_logloss: 0.263965\tvalid_0's auc: 0.936343\n",
      "[241]\tvalid_0's binary_logloss: 0.263797\tvalid_0's auc: 0.936539\n",
      "[242]\tvalid_0's binary_logloss: 0.263673\tvalid_0's auc: 0.936857\n",
      "[243]\tvalid_0's binary_logloss: 0.263455\tvalid_0's auc: 0.936954\n",
      "[244]\tvalid_0's binary_logloss: 0.262957\tvalid_0's auc: 0.937248\n",
      "[245]\tvalid_0's binary_logloss: 0.262152\tvalid_0's auc: 0.937761\n",
      "[246]\tvalid_0's binary_logloss: 0.262075\tvalid_0's auc: 0.938079\n",
      "[247]\tvalid_0's binary_logloss: 0.261731\tvalid_0's auc: 0.938128\n",
      "[248]\tvalid_0's binary_logloss: 0.261773\tvalid_0's auc: 0.937981\n",
      "[249]\tvalid_0's binary_logloss: 0.26199\tvalid_0's auc: 0.93781\n",
      "[250]\tvalid_0's binary_logloss: 0.261915\tvalid_0's auc: 0.937908\n",
      "[251]\tvalid_0's binary_logloss: 0.260951\tvalid_0's auc: 0.938348\n",
      "[252]\tvalid_0's binary_logloss: 0.260766\tvalid_0's auc: 0.938373\n",
      "[253]\tvalid_0's binary_logloss: 0.260578\tvalid_0's auc: 0.938764\n",
      "[254]\tvalid_0's binary_logloss: 0.259788\tvalid_0's auc: 0.939204\n",
      "[255]\tvalid_0's binary_logloss: 0.259777\tvalid_0's auc: 0.939253\n",
      "[256]\tvalid_0's binary_logloss: 0.25956\tvalid_0's auc: 0.939302\n",
      "[257]\tvalid_0's binary_logloss: 0.25985\tvalid_0's auc: 0.939155\n",
      "[258]\tvalid_0's binary_logloss: 0.259663\tvalid_0's auc: 0.939351\n",
      "[259]\tvalid_0's binary_logloss: 0.259308\tvalid_0's auc: 0.939596\n",
      "[260]\tvalid_0's binary_logloss: 0.259141\tvalid_0's auc: 0.939375\n",
      "[261]\tvalid_0's binary_logloss: 0.25898\tvalid_0's auc: 0.939498\n",
      "[262]\tvalid_0's binary_logloss: 0.258583\tvalid_0's auc: 0.939865\n",
      "[263]\tvalid_0's binary_logloss: 0.257777\tvalid_0's auc: 0.940305\n",
      "[264]\tvalid_0's binary_logloss: 0.25731\tvalid_0's auc: 0.940476\n",
      "[265]\tvalid_0's binary_logloss: 0.256983\tvalid_0's auc: 0.940574\n",
      "[266]\tvalid_0's binary_logloss: 0.256725\tvalid_0's auc: 0.940892\n",
      "[267]\tvalid_0's binary_logloss: 0.256648\tvalid_0's auc: 0.940965\n",
      "[268]\tvalid_0's binary_logloss: 0.256133\tvalid_0's auc: 0.941112\n",
      "[269]\tvalid_0's binary_logloss: 0.256029\tvalid_0's auc: 0.941136\n",
      "[270]\tvalid_0's binary_logloss: 0.25614\tvalid_0's auc: 0.940989\n",
      "[271]\tvalid_0's binary_logloss: 0.256049\tvalid_0's auc: 0.940745\n",
      "[272]\tvalid_0's binary_logloss: 0.255978\tvalid_0's auc: 0.941136\n",
      "[273]\tvalid_0's binary_logloss: 0.255847\tvalid_0's auc: 0.941185\n",
      "[274]\tvalid_0's binary_logloss: 0.256102\tvalid_0's auc: 0.940941\n",
      "[275]\tvalid_0's binary_logloss: 0.256137\tvalid_0's auc: 0.940892\n",
      "[276]\tvalid_0's binary_logloss: 0.256016\tvalid_0's auc: 0.940867\n",
      "[277]\tvalid_0's binary_logloss: 0.255904\tvalid_0's auc: 0.940794\n",
      "[278]\tvalid_0's binary_logloss: 0.255474\tvalid_0's auc: 0.940867\n",
      "[279]\tvalid_0's binary_logloss: 0.255426\tvalid_0's auc: 0.940672\n",
      "[280]\tvalid_0's binary_logloss: 0.255316\tvalid_0's auc: 0.940769\n",
      "[281]\tvalid_0's binary_logloss: 0.255283\tvalid_0's auc: 0.940892\n",
      "[282]\tvalid_0's binary_logloss: 0.255081\tvalid_0's auc: 0.941087\n",
      "[283]\tvalid_0's binary_logloss: 0.255194\tvalid_0's auc: 0.941185\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's binary_logloss: 0.255847\tvalid_0's auc: 0.941185\n",
      "3 time\n",
      "The score of the current model in the training set is: logloss=0.1959, auc=0.9767, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 920, number of negative: 3580\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1093\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 59\n",
      "[284]\tvalid_0's binary_logloss: 0.24251\tvalid_0's auc: 0.945681\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[285]\tvalid_0's binary_logloss: 0.241503\tvalid_0's auc: 0.946649\n",
      "[286]\tvalid_0's binary_logloss: 0.240517\tvalid_0's auc: 0.947666\n",
      "[287]\tvalid_0's binary_logloss: 0.240154\tvalid_0's auc: 0.947964\n",
      "[288]\tvalid_0's binary_logloss: 0.239235\tvalid_0's auc: 0.94856\n",
      "[289]\tvalid_0's binary_logloss: 0.239153\tvalid_0's auc: 0.948659\n",
      "[290]\tvalid_0's binary_logloss: 0.238052\tvalid_0's auc: 0.949279\n",
      "[291]\tvalid_0's binary_logloss: 0.238075\tvalid_0's auc: 0.949478\n",
      "[292]\tvalid_0's binary_logloss: 0.237376\tvalid_0's auc: 0.950024\n",
      "[293]\tvalid_0's binary_logloss: 0.237433\tvalid_0's auc: 0.95047\n",
      "[294]\tvalid_0's binary_logloss: 0.237415\tvalid_0's auc: 0.950619\n",
      "[295]\tvalid_0's binary_logloss: 0.236694\tvalid_0's auc: 0.951612\n",
      "[296]\tvalid_0's binary_logloss: 0.236066\tvalid_0's auc: 0.952207\n",
      "[297]\tvalid_0's binary_logloss: 0.235755\tvalid_0's auc: 0.952431\n",
      "[298]\tvalid_0's binary_logloss: 0.235526\tvalid_0's auc: 0.952952\n",
      "[299]\tvalid_0's binary_logloss: 0.234715\tvalid_0's auc: 0.953795\n",
      "[300]\tvalid_0's binary_logloss: 0.234763\tvalid_0's auc: 0.953448\n",
      "[301]\tvalid_0's binary_logloss: 0.233985\tvalid_0's auc: 0.954093\n",
      "[302]\tvalid_0's binary_logloss: 0.233815\tvalid_0's auc: 0.954341\n",
      "[303]\tvalid_0's binary_logloss: 0.23267\tvalid_0's auc: 0.955036\n",
      "[304]\tvalid_0's binary_logloss: 0.232642\tvalid_0's auc: 0.954862\n",
      "[305]\tvalid_0's binary_logloss: 0.232027\tvalid_0's auc: 0.955384\n",
      "[306]\tvalid_0's binary_logloss: 0.231425\tvalid_0's auc: 0.955756\n",
      "[307]\tvalid_0's binary_logloss: 0.230979\tvalid_0's auc: 0.95583\n",
      "[308]\tvalid_0's binary_logloss: 0.23076\tvalid_0's auc: 0.955979\n",
      "[309]\tvalid_0's binary_logloss: 0.23075\tvalid_0's auc: 0.956004\n",
      "[310]\tvalid_0's binary_logloss: 0.230625\tvalid_0's auc: 0.956153\n",
      "[311]\tvalid_0's binary_logloss: 0.229671\tvalid_0's auc: 0.956872\n",
      "[312]\tvalid_0's binary_logloss: 0.229308\tvalid_0's auc: 0.957245\n",
      "[313]\tvalid_0's binary_logloss: 0.22852\tvalid_0's auc: 0.957815\n",
      "[314]\tvalid_0's binary_logloss: 0.227693\tvalid_0's auc: 0.958088\n",
      "[315]\tvalid_0's binary_logloss: 0.226875\tvalid_0's auc: 0.958237\n",
      "[316]\tvalid_0's binary_logloss: 0.226642\tvalid_0's auc: 0.958212\n",
      "[317]\tvalid_0's binary_logloss: 0.226828\tvalid_0's auc: 0.958312\n",
      "[318]\tvalid_0's binary_logloss: 0.225506\tvalid_0's auc: 0.959453\n",
      "[319]\tvalid_0's binary_logloss: 0.225255\tvalid_0's auc: 0.959453\n",
      "[320]\tvalid_0's binary_logloss: 0.224851\tvalid_0's auc: 0.959676\n",
      "[321]\tvalid_0's binary_logloss: 0.224679\tvalid_0's auc: 0.959453\n",
      "[322]\tvalid_0's binary_logloss: 0.22392\tvalid_0's auc: 0.959652\n",
      "[323]\tvalid_0's binary_logloss: 0.223881\tvalid_0's auc: 0.959577\n",
      "[324]\tvalid_0's binary_logloss: 0.223675\tvalid_0's auc: 0.959751\n",
      "[325]\tvalid_0's binary_logloss: 0.222898\tvalid_0's auc: 0.9599\n",
      "[326]\tvalid_0's binary_logloss: 0.222872\tvalid_0's auc: 0.959875\n",
      "[327]\tvalid_0's binary_logloss: 0.222297\tvalid_0's auc: 0.960272\n",
      "[328]\tvalid_0's binary_logloss: 0.221858\tvalid_0's auc: 0.960595\n",
      "[329]\tvalid_0's binary_logloss: 0.221713\tvalid_0's auc: 0.960868\n",
      "[330]\tvalid_0's binary_logloss: 0.221385\tvalid_0's auc: 0.961041\n",
      "[331]\tvalid_0's binary_logloss: 0.220594\tvalid_0's auc: 0.961116\n",
      "[332]\tvalid_0's binary_logloss: 0.220379\tvalid_0's auc: 0.960992\n",
      "[333]\tvalid_0's binary_logloss: 0.220228\tvalid_0's auc: 0.960892\n",
      "[334]\tvalid_0's binary_logloss: 0.220407\tvalid_0's auc: 0.961066\n",
      "[335]\tvalid_0's binary_logloss: 0.219774\tvalid_0's auc: 0.961389\n",
      "[336]\tvalid_0's binary_logloss: 0.219282\tvalid_0's auc: 0.961587\n",
      "[337]\tvalid_0's binary_logloss: 0.218906\tvalid_0's auc: 0.962108\n",
      "[338]\tvalid_0's binary_logloss: 0.218385\tvalid_0's auc: 0.962183\n",
      "[339]\tvalid_0's binary_logloss: 0.21838\tvalid_0's auc: 0.962381\n",
      "[340]\tvalid_0's binary_logloss: 0.21828\tvalid_0's auc: 0.962555\n",
      "[341]\tvalid_0's binary_logloss: 0.217908\tvalid_0's auc: 0.962679\n",
      "[342]\tvalid_0's binary_logloss: 0.217576\tvalid_0's auc: 0.962803\n",
      "[343]\tvalid_0's binary_logloss: 0.217212\tvalid_0's auc: 0.962828\n",
      "[344]\tvalid_0's binary_logloss: 0.216698\tvalid_0's auc: 0.963175\n",
      "[345]\tvalid_0's binary_logloss: 0.216633\tvalid_0's auc: 0.963101\n",
      "[346]\tvalid_0's binary_logloss: 0.216515\tvalid_0's auc: 0.96315\n",
      "[347]\tvalid_0's binary_logloss: 0.215822\tvalid_0's auc: 0.963498\n",
      "[348]\tvalid_0's binary_logloss: 0.215201\tvalid_0's auc: 0.963945\n",
      "[349]\tvalid_0's binary_logloss: 0.214703\tvalid_0's auc: 0.964118\n",
      "[350]\tvalid_0's binary_logloss: 0.214415\tvalid_0's auc: 0.964217\n",
      "[351]\tvalid_0's binary_logloss: 0.214284\tvalid_0's auc: 0.964044\n",
      "[352]\tvalid_0's binary_logloss: 0.214031\tvalid_0's auc: 0.963945\n",
      "[353]\tvalid_0's binary_logloss: 0.213806\tvalid_0's auc: 0.964044\n",
      "[354]\tvalid_0's binary_logloss: 0.213693\tvalid_0's auc: 0.963845\n",
      "[355]\tvalid_0's binary_logloss: 0.213665\tvalid_0's auc: 0.963597\n",
      "[356]\tvalid_0's binary_logloss: 0.213147\tvalid_0's auc: 0.963969\n",
      "[357]\tvalid_0's binary_logloss: 0.213084\tvalid_0's auc: 0.963796\n",
      "[358]\tvalid_0's binary_logloss: 0.212994\tvalid_0's auc: 0.963796\n",
      "[359]\tvalid_0's binary_logloss: 0.212519\tvalid_0's auc: 0.96392\n",
      "[360]\tvalid_0's binary_logloss: 0.212615\tvalid_0's auc: 0.963746\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's binary_logloss: 0.214415\tvalid_0's auc: 0.964217\n",
      "4 time\n",
      "The score of the current model in the training set is: logloss=0.1769, auc=0.9828, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 871, number of negative: 3629\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1089\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 57\n",
      "[361]\tvalid_0's binary_logloss: 0.213236\tvalid_0's auc: 0.952544\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[362]\tvalid_0's binary_logloss: 0.21238\tvalid_0's auc: 0.953026\n",
      "[363]\tvalid_0's binary_logloss: 0.211989\tvalid_0's auc: 0.953168\n",
      "[364]\tvalid_0's binary_logloss: 0.211281\tvalid_0's auc: 0.953565\n",
      "[365]\tvalid_0's binary_logloss: 0.21053\tvalid_0's auc: 0.95382\n",
      "[366]\tvalid_0's binary_logloss: 0.210131\tvalid_0's auc: 0.954245\n",
      "[367]\tvalid_0's binary_logloss: 0.210312\tvalid_0's auc: 0.954103\n",
      "[368]\tvalid_0's binary_logloss: 0.210522\tvalid_0's auc: 0.953848\n",
      "[369]\tvalid_0's binary_logloss: 0.209676\tvalid_0's auc: 0.954387\n",
      "[370]\tvalid_0's binary_logloss: 0.209216\tvalid_0's auc: 0.954784\n",
      "[371]\tvalid_0's binary_logloss: 0.20897\tvalid_0's auc: 0.954926\n",
      "[372]\tvalid_0's binary_logloss: 0.209213\tvalid_0's auc: 0.954869\n",
      "[373]\tvalid_0's binary_logloss: 0.209096\tvalid_0's auc: 0.954841\n",
      "[374]\tvalid_0's binary_logloss: 0.208916\tvalid_0's auc: 0.955039\n",
      "[375]\tvalid_0's binary_logloss: 0.20822\tvalid_0's auc: 0.955719\n",
      "[376]\tvalid_0's binary_logloss: 0.207596\tvalid_0's auc: 0.956003\n",
      "[377]\tvalid_0's binary_logloss: 0.207215\tvalid_0's auc: 0.956513\n",
      "[378]\tvalid_0's binary_logloss: 0.20679\tvalid_0's auc: 0.956683\n",
      "[379]\tvalid_0's binary_logloss: 0.206477\tvalid_0's auc: 0.957023\n",
      "[380]\tvalid_0's binary_logloss: 0.205501\tvalid_0's auc: 0.957845\n",
      "[381]\tvalid_0's binary_logloss: 0.20503\tvalid_0's auc: 0.957931\n",
      "[382]\tvalid_0's binary_logloss: 0.204806\tvalid_0's auc: 0.957732\n",
      "[383]\tvalid_0's binary_logloss: 0.204743\tvalid_0's auc: 0.958044\n",
      "[384]\tvalid_0's binary_logloss: 0.204237\tvalid_0's auc: 0.958157\n",
      "[385]\tvalid_0's binary_logloss: 0.204133\tvalid_0's auc: 0.958101\n",
      "[386]\tvalid_0's binary_logloss: 0.20362\tvalid_0's auc: 0.958554\n",
      "[387]\tvalid_0's binary_logloss: 0.203395\tvalid_0's auc: 0.958668\n",
      "[388]\tvalid_0's binary_logloss: 0.20303\tvalid_0's auc: 0.958838\n",
      "[389]\tvalid_0's binary_logloss: 0.202987\tvalid_0's auc: 0.958412\n",
      "[390]\tvalid_0's binary_logloss: 0.202447\tvalid_0's auc: 0.958894\n",
      "[391]\tvalid_0's binary_logloss: 0.202568\tvalid_0's auc: 0.958894\n",
      "[392]\tvalid_0's binary_logloss: 0.202284\tvalid_0's auc: 0.958866\n",
      "[393]\tvalid_0's binary_logloss: 0.202213\tvalid_0's auc: 0.958979\n",
      "[394]\tvalid_0's binary_logloss: 0.201984\tvalid_0's auc: 0.958894\n",
      "[395]\tvalid_0's binary_logloss: 0.201504\tvalid_0's auc: 0.95932\n",
      "[396]\tvalid_0's binary_logloss: 0.201092\tvalid_0's auc: 0.959518\n",
      "[397]\tvalid_0's binary_logloss: 0.20074\tvalid_0's auc: 0.95983\n",
      "[398]\tvalid_0's binary_logloss: 0.200724\tvalid_0's auc: 0.960057\n",
      "[399]\tvalid_0's binary_logloss: 0.200414\tvalid_0's auc: 0.960369\n",
      "[400]\tvalid_0's binary_logloss: 0.20007\tvalid_0's auc: 0.960312\n",
      "[401]\tvalid_0's binary_logloss: 0.199693\tvalid_0's auc: 0.960595\n",
      "[402]\tvalid_0's binary_logloss: 0.199579\tvalid_0's auc: 0.960652\n",
      "[403]\tvalid_0's binary_logloss: 0.199592\tvalid_0's auc: 0.960936\n",
      "[404]\tvalid_0's binary_logloss: 0.199359\tvalid_0's auc: 0.960624\n",
      "[405]\tvalid_0's binary_logloss: 0.198927\tvalid_0's auc: 0.960822\n",
      "[406]\tvalid_0's binary_logloss: 0.199244\tvalid_0's auc: 0.960822\n",
      "[407]\tvalid_0's binary_logloss: 0.198849\tvalid_0's auc: 0.961276\n",
      "[408]\tvalid_0's binary_logloss: 0.198949\tvalid_0's auc: 0.961247\n",
      "[409]\tvalid_0's binary_logloss: 0.198681\tvalid_0's auc: 0.961502\n",
      "[410]\tvalid_0's binary_logloss: 0.198561\tvalid_0's auc: 0.961417\n",
      "[411]\tvalid_0's binary_logloss: 0.198431\tvalid_0's auc: 0.961616\n",
      "[412]\tvalid_0's binary_logloss: 0.198066\tvalid_0's auc: 0.961673\n",
      "[413]\tvalid_0's binary_logloss: 0.197982\tvalid_0's auc: 0.961616\n",
      "[414]\tvalid_0's binary_logloss: 0.197845\tvalid_0's auc: 0.961786\n",
      "[415]\tvalid_0's binary_logloss: 0.197461\tvalid_0's auc: 0.961701\n",
      "[416]\tvalid_0's binary_logloss: 0.197647\tvalid_0's auc: 0.961701\n",
      "[417]\tvalid_0's binary_logloss: 0.197503\tvalid_0's auc: 0.961673\n",
      "[418]\tvalid_0's binary_logloss: 0.197784\tvalid_0's auc: 0.961616\n",
      "[419]\tvalid_0's binary_logloss: 0.197708\tvalid_0's auc: 0.961616\n",
      "[420]\tvalid_0's binary_logloss: 0.197792\tvalid_0's auc: 0.961417\n",
      "[421]\tvalid_0's binary_logloss: 0.197777\tvalid_0's auc: 0.961276\n",
      "[422]\tvalid_0's binary_logloss: 0.197478\tvalid_0's auc: 0.961247\n",
      "[423]\tvalid_0's binary_logloss: 0.197181\tvalid_0's auc: 0.961417\n",
      "[424]\tvalid_0's binary_logloss: 0.197003\tvalid_0's auc: 0.961474\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's binary_logloss: 0.197845\tvalid_0's auc: 0.961786\n",
      "5 time\n",
      "The score of the current model in the training set is: logloss=0.1670, auc=0.9844, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 921, number of negative: 3579\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1097\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 56\n",
      "[425]\tvalid_0's binary_logloss: 0.228626\tvalid_0's auc: 0.950886\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[426]\tvalid_0's binary_logloss: 0.227268\tvalid_0's auc: 0.951653\n",
      "[427]\tvalid_0's binary_logloss: 0.226016\tvalid_0's auc: 0.951943\n",
      "[428]\tvalid_0's binary_logloss: 0.225371\tvalid_0's auc: 0.952155\n",
      "[429]\tvalid_0's binary_logloss: 0.224877\tvalid_0's auc: 0.952445\n",
      "[430]\tvalid_0's binary_logloss: 0.224159\tvalid_0's auc: 0.952947\n",
      "[431]\tvalid_0's binary_logloss: 0.223392\tvalid_0's auc: 0.953053\n",
      "[432]\tvalid_0's binary_logloss: 0.222742\tvalid_0's auc: 0.953317\n",
      "[433]\tvalid_0's binary_logloss: 0.222499\tvalid_0's auc: 0.953396\n",
      "[434]\tvalid_0's binary_logloss: 0.222\tvalid_0's auc: 0.95374\n",
      "[435]\tvalid_0's binary_logloss: 0.221667\tvalid_0's auc: 0.953898\n",
      "[436]\tvalid_0's binary_logloss: 0.221212\tvalid_0's auc: 0.954215\n",
      "[437]\tvalid_0's binary_logloss: 0.221262\tvalid_0's auc: 0.954057\n",
      "[438]\tvalid_0's binary_logloss: 0.220936\tvalid_0's auc: 0.954083\n",
      "[439]\tvalid_0's binary_logloss: 0.221053\tvalid_0's auc: 0.954057\n",
      "[440]\tvalid_0's binary_logloss: 0.220931\tvalid_0's auc: 0.954136\n",
      "[441]\tvalid_0's binary_logloss: 0.220185\tvalid_0's auc: 0.954427\n",
      "[442]\tvalid_0's binary_logloss: 0.21972\tvalid_0's auc: 0.954585\n",
      "[443]\tvalid_0's binary_logloss: 0.219599\tvalid_0's auc: 0.954427\n",
      "[444]\tvalid_0's binary_logloss: 0.219278\tvalid_0's auc: 0.954427\n",
      "[445]\tvalid_0's binary_logloss: 0.219125\tvalid_0's auc: 0.954215\n",
      "[446]\tvalid_0's binary_logloss: 0.218792\tvalid_0's auc: 0.954585\n",
      "[447]\tvalid_0's binary_logloss: 0.218695\tvalid_0's auc: 0.954453\n",
      "[448]\tvalid_0's binary_logloss: 0.218785\tvalid_0's auc: 0.954453\n",
      "[449]\tvalid_0's binary_logloss: 0.218329\tvalid_0's auc: 0.954902\n",
      "[450]\tvalid_0's binary_logloss: 0.217723\tvalid_0's auc: 0.955298\n",
      "[451]\tvalid_0's binary_logloss: 0.217204\tvalid_0's auc: 0.955431\n",
      "[452]\tvalid_0's binary_logloss: 0.216717\tvalid_0's auc: 0.9558\n",
      "[453]\tvalid_0's binary_logloss: 0.216719\tvalid_0's auc: 0.955642\n",
      "[454]\tvalid_0's binary_logloss: 0.216538\tvalid_0's auc: 0.955985\n",
      "[455]\tvalid_0's binary_logloss: 0.215848\tvalid_0's auc: 0.956434\n",
      "[456]\tvalid_0's binary_logloss: 0.215613\tvalid_0's auc: 0.956672\n",
      "[457]\tvalid_0's binary_logloss: 0.215313\tvalid_0's auc: 0.956831\n",
      "[458]\tvalid_0's binary_logloss: 0.215291\tvalid_0's auc: 0.956804\n",
      "[459]\tvalid_0's binary_logloss: 0.214786\tvalid_0's auc: 0.956989\n",
      "[460]\tvalid_0's binary_logloss: 0.214378\tvalid_0's auc: 0.957069\n",
      "[461]\tvalid_0's binary_logloss: 0.214191\tvalid_0's auc: 0.957253\n",
      "[462]\tvalid_0's binary_logloss: 0.213769\tvalid_0's auc: 0.957597\n",
      "[463]\tvalid_0's binary_logloss: 0.213984\tvalid_0's auc: 0.957253\n",
      "[464]\tvalid_0's binary_logloss: 0.213937\tvalid_0's auc: 0.957333\n",
      "[465]\tvalid_0's binary_logloss: 0.213386\tvalid_0's auc: 0.957676\n",
      "[466]\tvalid_0's binary_logloss: 0.212815\tvalid_0's auc: 0.958099\n",
      "[467]\tvalid_0's binary_logloss: 0.21278\tvalid_0's auc: 0.958178\n",
      "[468]\tvalid_0's binary_logloss: 0.212418\tvalid_0's auc: 0.958152\n",
      "[469]\tvalid_0's binary_logloss: 0.21233\tvalid_0's auc: 0.958257\n",
      "[470]\tvalid_0's binary_logloss: 0.21206\tvalid_0's auc: 0.958363\n",
      "[471]\tvalid_0's binary_logloss: 0.211843\tvalid_0's auc: 0.958416\n",
      "[472]\tvalid_0's binary_logloss: 0.211719\tvalid_0's auc: 0.958442\n",
      "[473]\tvalid_0's binary_logloss: 0.211116\tvalid_0's auc: 0.958707\n",
      "[474]\tvalid_0's binary_logloss: 0.210861\tvalid_0's auc: 0.958944\n",
      "[475]\tvalid_0's binary_logloss: 0.210812\tvalid_0's auc: 0.959076\n",
      "[476]\tvalid_0's binary_logloss: 0.210697\tvalid_0's auc: 0.959129\n",
      "[477]\tvalid_0's binary_logloss: 0.210514\tvalid_0's auc: 0.959182\n",
      "[478]\tvalid_0's binary_logloss: 0.210127\tvalid_0's auc: 0.959499\n",
      "[479]\tvalid_0's binary_logloss: 0.2102\tvalid_0's auc: 0.959261\n",
      "[480]\tvalid_0's binary_logloss: 0.209555\tvalid_0's auc: 0.959737\n",
      "[481]\tvalid_0's binary_logloss: 0.209641\tvalid_0's auc: 0.95971\n",
      "[482]\tvalid_0's binary_logloss: 0.209601\tvalid_0's auc: 0.959684\n",
      "[483]\tvalid_0's binary_logloss: 0.209386\tvalid_0's auc: 0.95971\n",
      "[484]\tvalid_0's binary_logloss: 0.209205\tvalid_0's auc: 0.95971\n",
      "[485]\tvalid_0's binary_logloss: 0.209155\tvalid_0's auc: 0.959869\n",
      "[486]\tvalid_0's binary_logloss: 0.209119\tvalid_0's auc: 0.959763\n",
      "[487]\tvalid_0's binary_logloss: 0.208905\tvalid_0's auc: 0.959869\n",
      "[488]\tvalid_0's binary_logloss: 0.208586\tvalid_0's auc: 0.960027\n",
      "[489]\tvalid_0's binary_logloss: 0.208842\tvalid_0's auc: 0.959895\n",
      "[490]\tvalid_0's binary_logloss: 0.208935\tvalid_0's auc: 0.959975\n",
      "[491]\tvalid_0's binary_logloss: 0.208738\tvalid_0's auc: 0.959922\n",
      "[492]\tvalid_0's binary_logloss: 0.208496\tvalid_0's auc: 0.960186\n",
      "[493]\tvalid_0's binary_logloss: 0.208208\tvalid_0's auc: 0.96045\n",
      "[494]\tvalid_0's binary_logloss: 0.20827\tvalid_0's auc: 0.960529\n",
      "[495]\tvalid_0's binary_logloss: 0.208407\tvalid_0's auc: 0.960662\n",
      "[496]\tvalid_0's binary_logloss: 0.208383\tvalid_0's auc: 0.960662\n",
      "[497]\tvalid_0's binary_logloss: 0.208462\tvalid_0's auc: 0.960635\n",
      "[498]\tvalid_0's binary_logloss: 0.208268\tvalid_0's auc: 0.960899\n",
      "[499]\tvalid_0's binary_logloss: 0.208294\tvalid_0's auc: 0.960741\n",
      "[500]\tvalid_0's binary_logloss: 0.208137\tvalid_0's auc: 0.960952\n",
      "[501]\tvalid_0's binary_logloss: 0.207757\tvalid_0's auc: 0.961111\n",
      "[502]\tvalid_0's binary_logloss: 0.207213\tvalid_0's auc: 0.961216\n",
      "[503]\tvalid_0's binary_logloss: 0.207125\tvalid_0's auc: 0.961269\n",
      "[504]\tvalid_0's binary_logloss: 0.20699\tvalid_0's auc: 0.961375\n",
      "[505]\tvalid_0's binary_logloss: 0.206764\tvalid_0's auc: 0.961401\n",
      "[506]\tvalid_0's binary_logloss: 0.20685\tvalid_0's auc: 0.961322\n",
      "[507]\tvalid_0's binary_logloss: 0.206481\tvalid_0's auc: 0.961454\n",
      "[508]\tvalid_0's binary_logloss: 0.205721\tvalid_0's auc: 0.961956\n",
      "[509]\tvalid_0's binary_logloss: 0.205013\tvalid_0's auc: 0.962511\n",
      "[510]\tvalid_0's binary_logloss: 0.205232\tvalid_0's auc: 0.962511\n",
      "[511]\tvalid_0's binary_logloss: 0.20536\tvalid_0's auc: 0.962379\n",
      "[512]\tvalid_0's binary_logloss: 0.205272\tvalid_0's auc: 0.962405\n",
      "[513]\tvalid_0's binary_logloss: 0.205275\tvalid_0's auc: 0.962273\n",
      "[514]\tvalid_0's binary_logloss: 0.205259\tvalid_0's auc: 0.962326\n",
      "[515]\tvalid_0's binary_logloss: 0.205331\tvalid_0's auc: 0.962405\n",
      "[516]\tvalid_0's binary_logloss: 0.204904\tvalid_0's auc: 0.962484\n",
      "[517]\tvalid_0's binary_logloss: 0.204891\tvalid_0's auc: 0.962352\n",
      "[518]\tvalid_0's binary_logloss: 0.205093\tvalid_0's auc: 0.962167\n",
      "[519]\tvalid_0's binary_logloss: 0.205079\tvalid_0's auc: 0.962167\n",
      "Early stopping, best iteration is:\n",
      "[509]\tvalid_0's binary_logloss: 0.205013\tvalid_0's auc: 0.962511\n",
      "6 time\n",
      "The score of the current model in the training set is: logloss=0.1418, auc=0.9920, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 896, number of negative: 3604\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1096\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 60\n",
      "[520]\tvalid_0's binary_logloss: 0.209615\tvalid_0's auc: 0.964639\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[521]\tvalid_0's binary_logloss: 0.208861\tvalid_0's auc: 0.964872\n",
      "[522]\tvalid_0's binary_logloss: 0.208102\tvalid_0's auc: 0.965012\n",
      "[523]\tvalid_0's binary_logloss: 0.208187\tvalid_0's auc: 0.965058\n",
      "[524]\tvalid_0's binary_logloss: 0.207581\tvalid_0's auc: 0.965152\n",
      "[525]\tvalid_0's binary_logloss: 0.207125\tvalid_0's auc: 0.965408\n",
      "[526]\tvalid_0's binary_logloss: 0.206438\tvalid_0's auc: 0.965781\n",
      "[527]\tvalid_0's binary_logloss: 0.205838\tvalid_0's auc: 0.966224\n",
      "[528]\tvalid_0's binary_logloss: 0.205213\tvalid_0's auc: 0.966527\n",
      "[529]\tvalid_0's binary_logloss: 0.20505\tvalid_0's auc: 0.966434\n",
      "[530]\tvalid_0's binary_logloss: 0.204696\tvalid_0's auc: 0.96655\n",
      "[531]\tvalid_0's binary_logloss: 0.204041\tvalid_0's auc: 0.966737\n",
      "[532]\tvalid_0's binary_logloss: 0.203629\tvalid_0's auc: 0.96704\n",
      "[533]\tvalid_0's binary_logloss: 0.203536\tvalid_0's auc: 0.96704\n",
      "[534]\tvalid_0's binary_logloss: 0.203301\tvalid_0's auc: 0.967156\n",
      "[535]\tvalid_0's binary_logloss: 0.203476\tvalid_0's auc: 0.967273\n",
      "[536]\tvalid_0's binary_logloss: 0.2029\tvalid_0's auc: 0.967179\n",
      "[537]\tvalid_0's binary_logloss: 0.203002\tvalid_0's auc: 0.967086\n",
      "[538]\tvalid_0's binary_logloss: 0.202681\tvalid_0's auc: 0.967343\n",
      "[539]\tvalid_0's binary_logloss: 0.202761\tvalid_0's auc: 0.967389\n",
      "[540]\tvalid_0's binary_logloss: 0.202684\tvalid_0's auc: 0.967483\n",
      "[541]\tvalid_0's binary_logloss: 0.202793\tvalid_0's auc: 0.967133\n",
      "[542]\tvalid_0's binary_logloss: 0.20241\tvalid_0's auc: 0.967436\n",
      "[543]\tvalid_0's binary_logloss: 0.202387\tvalid_0's auc: 0.967249\n",
      "[544]\tvalid_0's binary_logloss: 0.201908\tvalid_0's auc: 0.967389\n",
      "[545]\tvalid_0's binary_logloss: 0.202213\tvalid_0's auc: 0.967343\n",
      "[546]\tvalid_0's binary_logloss: 0.202189\tvalid_0's auc: 0.967436\n",
      "[547]\tvalid_0's binary_logloss: 0.201887\tvalid_0's auc: 0.967552\n",
      "[548]\tvalid_0's binary_logloss: 0.201688\tvalid_0's auc: 0.967599\n",
      "[549]\tvalid_0's binary_logloss: 0.201651\tvalid_0's auc: 0.967436\n",
      "[550]\tvalid_0's binary_logloss: 0.201353\tvalid_0's auc: 0.967669\n",
      "[551]\tvalid_0's binary_logloss: 0.201038\tvalid_0's auc: 0.967716\n",
      "[552]\tvalid_0's binary_logloss: 0.200775\tvalid_0's auc: 0.967809\n",
      "[553]\tvalid_0's binary_logloss: 0.200728\tvalid_0's auc: 0.967855\n",
      "[554]\tvalid_0's binary_logloss: 0.200647\tvalid_0's auc: 0.967855\n",
      "[555]\tvalid_0's binary_logloss: 0.199962\tvalid_0's auc: 0.968182\n",
      "[556]\tvalid_0's binary_logloss: 0.199942\tvalid_0's auc: 0.968135\n",
      "[557]\tvalid_0's binary_logloss: 0.200049\tvalid_0's auc: 0.968089\n",
      "[558]\tvalid_0's binary_logloss: 0.199587\tvalid_0's auc: 0.968345\n",
      "[559]\tvalid_0's binary_logloss: 0.19929\tvalid_0's auc: 0.968531\n",
      "[560]\tvalid_0's binary_logloss: 0.19894\tvalid_0's auc: 0.968555\n",
      "[561]\tvalid_0's binary_logloss: 0.199061\tvalid_0's auc: 0.968508\n",
      "[562]\tvalid_0's binary_logloss: 0.19913\tvalid_0's auc: 0.968485\n",
      "[563]\tvalid_0's binary_logloss: 0.198772\tvalid_0's auc: 0.968578\n",
      "[564]\tvalid_0's binary_logloss: 0.19859\tvalid_0's auc: 0.968788\n",
      "[565]\tvalid_0's binary_logloss: 0.198386\tvalid_0's auc: 0.968695\n",
      "[566]\tvalid_0's binary_logloss: 0.19838\tvalid_0's auc: 0.968601\n",
      "[567]\tvalid_0's binary_logloss: 0.198452\tvalid_0's auc: 0.968462\n",
      "[568]\tvalid_0's binary_logloss: 0.198292\tvalid_0's auc: 0.968531\n",
      "[569]\tvalid_0's binary_logloss: 0.198021\tvalid_0's auc: 0.968741\n",
      "[570]\tvalid_0's binary_logloss: 0.198295\tvalid_0's auc: 0.968578\n",
      "[571]\tvalid_0's binary_logloss: 0.198212\tvalid_0's auc: 0.968438\n",
      "[572]\tvalid_0's binary_logloss: 0.198053\tvalid_0's auc: 0.968415\n",
      "[573]\tvalid_0's binary_logloss: 0.197943\tvalid_0's auc: 0.968438\n",
      "[574]\tvalid_0's binary_logloss: 0.197605\tvalid_0's auc: 0.968648\n",
      "Early stopping, best iteration is:\n",
      "[564]\tvalid_0's binary_logloss: 0.19859\tvalid_0's auc: 0.968788\n",
      "7 time\n",
      "The score of the current model in the training set is: logloss=0.1471, auc=0.9893, \n",
      "\n",
      "[LightGBM] [Info] Number of positive: 860, number of negative: 3640\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1105\n",
      "[LightGBM] [Info] Number of data points in the train set: 4500, number of used features: 62\n",
      "[575]\tvalid_0's binary_logloss: 0.210323\tvalid_0's auc: 0.96291\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[576]\tvalid_0's binary_logloss: 0.209585\tvalid_0's auc: 0.96339\n",
      "[577]\tvalid_0's binary_logloss: 0.209404\tvalid_0's auc: 0.963756\n",
      "[578]\tvalid_0's binary_logloss: 0.20892\tvalid_0's auc: 0.963664\n",
      "[579]\tvalid_0's binary_logloss: 0.208266\tvalid_0's auc: 0.96403\n",
      "[580]\tvalid_0's binary_logloss: 0.20778\tvalid_0's auc: 0.964122\n",
      "[581]\tvalid_0's binary_logloss: 0.207338\tvalid_0's auc: 0.964236\n",
      "[582]\tvalid_0's binary_logloss: 0.207163\tvalid_0's auc: 0.964602\n",
      "[583]\tvalid_0's binary_logloss: 0.206913\tvalid_0's auc: 0.964465\n",
      "[584]\tvalid_0's binary_logloss: 0.206579\tvalid_0's auc: 0.964396\n",
      "[585]\tvalid_0's binary_logloss: 0.206559\tvalid_0's auc: 0.964373\n",
      "[586]\tvalid_0's binary_logloss: 0.206319\tvalid_0's auc: 0.964556\n",
      "[587]\tvalid_0's binary_logloss: 0.205619\tvalid_0's auc: 0.964762\n",
      "[588]\tvalid_0's binary_logloss: 0.20555\tvalid_0's auc: 0.965013\n",
      "[589]\tvalid_0's binary_logloss: 0.205174\tvalid_0's auc: 0.965654\n",
      "[590]\tvalid_0's binary_logloss: 0.204677\tvalid_0's auc: 0.966088\n",
      "[591]\tvalid_0's binary_logloss: 0.204409\tvalid_0's auc: 0.96618\n",
      "[592]\tvalid_0's binary_logloss: 0.20441\tvalid_0's auc: 0.966088\n",
      "[593]\tvalid_0's binary_logloss: 0.204011\tvalid_0's auc: 0.966637\n",
      "[594]\tvalid_0's binary_logloss: 0.203559\tvalid_0's auc: 0.966866\n",
      "[595]\tvalid_0's binary_logloss: 0.203581\tvalid_0's auc: 0.96698\n",
      "[596]\tvalid_0's binary_logloss: 0.203321\tvalid_0's auc: 0.967186\n",
      "[597]\tvalid_0's binary_logloss: 0.203244\tvalid_0's auc: 0.967094\n",
      "[598]\tvalid_0's binary_logloss: 0.203154\tvalid_0's auc: 0.967163\n",
      "[599]\tvalid_0's binary_logloss: 0.203122\tvalid_0's auc: 0.967186\n",
      "[600]\tvalid_0's binary_logloss: 0.202848\tvalid_0's auc: 0.967735\n",
      "[601]\tvalid_0's binary_logloss: 0.20275\tvalid_0's auc: 0.967643\n",
      "[602]\tvalid_0's binary_logloss: 0.202942\tvalid_0's auc: 0.967529\n",
      "[603]\tvalid_0's binary_logloss: 0.202571\tvalid_0's auc: 0.967643\n",
      "[604]\tvalid_0's binary_logloss: 0.201794\tvalid_0's auc: 0.967963\n",
      "[605]\tvalid_0's binary_logloss: 0.201669\tvalid_0's auc: 0.968238\n",
      "[606]\tvalid_0's binary_logloss: 0.201635\tvalid_0's auc: 0.968329\n",
      "[607]\tvalid_0's binary_logloss: 0.201075\tvalid_0's auc: 0.968741\n",
      "[608]\tvalid_0's binary_logloss: 0.201603\tvalid_0's auc: 0.968466\n",
      "[609]\tvalid_0's binary_logloss: 0.201198\tvalid_0's auc: 0.968649\n",
      "[610]\tvalid_0's binary_logloss: 0.201042\tvalid_0's auc: 0.968581\n",
      "[611]\tvalid_0's binary_logloss: 0.201203\tvalid_0's auc: 0.968604\n",
      "[612]\tvalid_0's binary_logloss: 0.200975\tvalid_0's auc: 0.968535\n",
      "[613]\tvalid_0's binary_logloss: 0.200641\tvalid_0's auc: 0.968672\n",
      "[614]\tvalid_0's binary_logloss: 0.200445\tvalid_0's auc: 0.968832\n",
      "[615]\tvalid_0's binary_logloss: 0.200291\tvalid_0's auc: 0.968947\n",
      "[616]\tvalid_0's binary_logloss: 0.200401\tvalid_0's auc: 0.969221\n",
      "[617]\tvalid_0's binary_logloss: 0.200042\tvalid_0's auc: 0.969175\n",
      "[618]\tvalid_0's binary_logloss: 0.200248\tvalid_0's auc: 0.969152\n",
      "[619]\tvalid_0's binary_logloss: 0.200372\tvalid_0's auc: 0.968992\n",
      "[620]\tvalid_0's binary_logloss: 0.200584\tvalid_0's auc: 0.968878\n",
      "[621]\tvalid_0's binary_logloss: 0.200925\tvalid_0's auc: 0.968695\n",
      "[622]\tvalid_0's binary_logloss: 0.200899\tvalid_0's auc: 0.968764\n",
      "[623]\tvalid_0's binary_logloss: 0.200858\tvalid_0's auc: 0.968695\n",
      "[624]\tvalid_0's binary_logloss: 0.200676\tvalid_0's auc: 0.968626\n",
      "[625]\tvalid_0's binary_logloss: 0.200576\tvalid_0's auc: 0.968604\n",
      "[626]\tvalid_0's binary_logloss: 0.200528\tvalid_0's auc: 0.968626\n",
      "Early stopping, best iteration is:\n",
      "[616]\tvalid_0's binary_logloss: 0.200401\tvalid_0's auc: 0.969221\n",
      "8 time\n",
      "The score of the current model in the training set is: logloss=0.1333, auc=0.9916, \n",
      "\n",
      "F1 score: 0.8218657661460532\n",
      "------------------------------------------\n",
      "Precision: 0.8428571428571429\n",
      "------------------------------------------\n",
      "Recall: 0.8018945634266886\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "gbm = IncrementaLightGbm(train_X, train_y)\n",
    "pred_y = gbm.predict(test_X)\n",
    "pred_classes = np.where(pred_y > 0.5, 1, 0)\n",
    "print(f'F1 score: {f1_score(test_y, pred_classes)}')\n",
    "print('------------------------------------------')\n",
    "print(f'Precision: {precision_score(test_y, pred_classes)}')\n",
    "print('------------------------------------------')\n",
    "print(f'Recall: {recall_score(test_y, pred_classes)}')\n",
    "\n",
    "joblib.dump(gbm, 'loan_model.pkl')\n",
    "gbm = joblib.load('loan_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8218657661460532\n",
      "------------------------------------------\n",
      "Precision: 0.8428571428571429\n",
      "------------------------------------------\n",
      "Recall: 0.8018945634266886\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 score: {f1_score(test_y, pred_classes)}')\n",
    "print('------------------------------------------')\n",
    "print(f'Precision: {precision_score(test_y, pred_classes)}')\n",
    "print('------------------------------------------')\n",
    "print(f'Recall: {recall_score(test_y, pred_classes)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
