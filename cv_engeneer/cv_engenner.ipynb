{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Project\\lessons\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Библиотеки для обработки табличных данных\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Библиотеки для визуализации графиков и изображений/\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "# Библиотеки для обучения моделей\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Библиотека для работы с операционной системой\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Библиотека для парсинга XML-файлов\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "#Вспомогательные библиотеки\n",
    "from tqdm.auto import tqdm\n",
    "import shutil as sh\n",
    "import warnings\n",
    "\n",
    "# Игнорируем возникающие предупреждения\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее проверим, что для обучения моделей доступен графический ускоритель. Для этого воспользуемся встроенными возможностями PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Узнаем название видеокарты\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m## True\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m## Tesla T4\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:493\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Проверим, что нам доступна видеокарта\n",
    "print(torch.cuda.is_available())\n",
    "# Узнаем название видеокарты\n",
    "print(torch.cuda.get_device_name(0))\n",
    "## True\n",
    "## Tesla T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "## /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/car-plate-detection\\annotations\n",
      "/kaggle/input/car-plate-detection\\images\n"
     ]
    }
   ],
   "source": [
    "# Путь до папки с датасетом\n",
    "DATASET_PATH = \"/kaggle/input/car-plate-detection\"\n",
    "# Путь до папки с аннотациями\n",
    "ANNOTATIONS_PATH = os.path.join(DATASET_PATH, \"annotations\")\n",
    "# Путь до папки с изображениями\n",
    "IMAGES_PATH = os.path.join(DATASET_PATH, \"images\")\n",
    "\n",
    "print(ANNOTATIONS_PATH)\n",
    "print(IMAGES_PATH)\n",
    "\n",
    "## /kaggle/input/car-plate-detection/annotations\n",
    "## /kaggle/input/car-plate-detection/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/car-plate-detection\\\\images\\\\Cars129.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMAGES_PATH, image_filename)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Читаем изображение\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Создаём фигуру и координатную плоскость\u001b[39;00m\n\u001b[0;32m      7\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\matplotlib\\pyplot.py:2404\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2400\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[0;32m   2401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\n\u001b[0;32m   2402\u001b[0m         fname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath \u001b[38;5;241m|\u001b[39m BinaryIO, \u001b[38;5;28mformat\u001b[39m: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2403\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\matplotlib\\image.py:1525\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1524\u001b[0m         )\n\u001b[1;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimg_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1527\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1528\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32mc:\\Project\\lessons\\.venv\\Lib\\site-packages\\PIL\\ImageFile.py:125\u001b[0m, in \u001b[0;36mImageFile.__init__\u001b[1;34m(self, fp, filename)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodermaxblock \u001b[38;5;241m=\u001b[39m MAXBLOCK\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;66;03m# filename\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/car-plate-detection\\\\images\\\\Cars129.png'"
     ]
    }
   ],
   "source": [
    "# Составляем путь до файла: /путь/до/папки/имя_изображения.png\n",
    "image_filename = 'Cars129.png'\n",
    "image_path = os.path.join(IMAGES_PATH, image_filename)\n",
    "# Читаем изображение\n",
    "img = plt.imread(image_path)\n",
    "# Создаём фигуру и координатную плоскость\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# Выводим изображение на экран\n",
    "ax.imshow(img);\n",
    "# Выводим размер изображения\n",
    "print('Image shape: {}'.format(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем словарь, на основе которого затем создадим DataFrame\n",
    "df_dict = {\n",
    "    \"filename\":[], \"xmin\":[], \"ymin\":[],   \n",
    "    \"xmax\":[],\"ymax\":[], \"name\":[],    \n",
    "    \"width\":[], \"height\":[],\n",
    "}\n",
    "\n",
    "# Создаём цикл по всем аннотациям \n",
    "for annotation in glob.glob(ANNOTATIONS_PATH+\"/*.xml\"):\n",
    "    # Читаем XML-файл с аннотацией\n",
    "    tree = ET.parse(annotation)\n",
    "    # Находим тег, соответствующий имени файла\n",
    "    filename = tree.find('filename').text\n",
    "    # Создаём цикл по всем элементам XML-файла\n",
    "    for elem in tree.iter():\n",
    "        # Извлекаем из аннотации информацию о размере изображения — ширину и высоту\n",
    "        if 'size' in elem.tag:\n",
    "            for attr in list(elem):\n",
    "                if 'width' in attr.tag: \n",
    "                    width = int(round(float(attr.text)))\n",
    "                if 'height' in attr.tag:\n",
    "                    height = int(round(float(attr.text)))    \n",
    "        # Извлекаем информацию об изображении — имя класса и информацию о координатах bounding box\n",
    "        if 'object' in elem.tag:\n",
    "            for attr in list(elem):\n",
    "                if 'name' in attr.tag:\n",
    "                    name = attr.text                 \n",
    "                    df_dict['name'] += [name]\n",
    "                    df_dict['width'] += [width]\n",
    "                    df_dict['height'] += [height] \n",
    "                    df_dict['filename'] += [filename]\n",
    "\n",
    "\n",
    "                if 'bndbox' in attr.tag:\n",
    "                    for dim in list(attr):\n",
    "                        if 'xmin' in dim.tag:\n",
    "                            xmin = int(round(float(dim.text)))\n",
    "                            df_dict['xmin'] += [xmin]\n",
    "                        if 'ymin' in dim.tag:\n",
    "                            ymin = int(round(float(dim.text)))\n",
    "                            df_dict['ymin'] += [ymin]                                \n",
    "                        if 'xmax' in dim.tag:\n",
    "                            xmax = int(round(float(dim.text)))\n",
    "                            df_dict['xmax'] += [xmax]                                \n",
    "                        if 'ymax' in dim.tag:\n",
    "                            ymax = int(round(float(dim.text)))\n",
    "                            df_dict['ymax'] += [ymax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data shape: {}'.format(df.shape))\n",
    "print('Count of unique images: {}'.format(df['filename'].nunique()))\n",
    "print('Count of classes: {}'.format(df['name'].unique()))\n",
    "## Data shape: (471, 8)\n",
    "## Count of unique images: 433\n",
    "## Count of classes: ['licence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Составляем путь до файла — /путь/до/папки/имя_изображения.png\n",
    "image_filename = 'Cars129.png'\n",
    "image_path = os.path.join(IMAGES_PATH, image_filename)\n",
    "# Читаем изображение\n",
    "img = plt.imread(image_path)\n",
    "# Создаём фигуру и координатную плоскость\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# Выводим изображение на экран\n",
    "ax.imshow(img);\n",
    "\n",
    "# Находим индекс картинки в DataFrame\n",
    "image_idx = df[df['filename'] == image_filename].index\n",
    "\n",
    "# Находим координаты левой нижней точки\n",
    "x_min = df.loc[image_idx, 'xmin'].values\n",
    "y_min = df.loc[image_idx, 'ymin'].values\n",
    "# Находим ширину и высоту рамки\n",
    "box_width = (df.loc[image_idx, 'xmax'] - df.loc[image_idx, 'xmin']).values\n",
    "box_height = (df.loc[image_idx, 'ymax'] - df.loc[image_idx, 'ymin']).values\n",
    "print(x_min, y_min, box_width, box_height)\n",
    "\n",
    "# Так как ограничивающих прямоугольников может быть несколько, создаём цикл по всем.\n",
    "for i in range(len(image_idx)):\n",
    "    # Строим прямоугольник\n",
    "    rect = patches.Rectangle(\n",
    "        (x_min[i], y_min[i]), #координаты опорной точки\n",
    "        box_width[i], #ширина прямоугольника\n",
    "        box_height[i], #высота прямоугольника\n",
    "        linewidth=3, #ширина линии\n",
    "        edgecolor='r', #цвет\n",
    "        facecolor='none' #заливка (none — отсутствует)\n",
    "    )\n",
    "    # Накладываем прямоугольник поверх изображения\n",
    "    ax.add_patch(rect);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bounding_box(image_folder, image_filename, df=df):\n",
    "    # Создаём полный путь до изображения\n",
    "    image_path = os.path.join(image_folder, image_filename)\n",
    "    # Читаем изображение\n",
    "    img = plt.imread(image_path)\n",
    "    # Создаём фигуру и координатную плоскость\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    # Выводим изображение на экран\n",
    "    ax.imshow(img);\n",
    "\n",
    "    # Находим индекс изображения в DataFrame\n",
    "    image_idx = df[df['filename'] == image_filename].index\n",
    "\n",
    "    # Находим координаты левой нижней точки\n",
    "    x_min = df.loc[image_idx, 'xmin'].values\n",
    "    y_min = df.loc[image_idx, 'ymin'].values\n",
    "    # Находим ширину и высоту рамки\n",
    "    box_width = (df.loc[image_idx, 'xmax'] - df.loc[image_idx, 'xmin']).values\n",
    "    box_height = (df.loc[image_idx, 'ymax'] - df.loc[image_idx, 'ymin']).values\n",
    "    # Так как ограничивающих прямоугольников может быть несколько, создаём цикл по всем.\n",
    "    for i in range(len(image_idx)):\n",
    "        # Строим прямоугольник\n",
    "        rect = patches.Rectangle(\n",
    "            (x_min[i], y_min[i]), #координаты опорной точки\n",
    "            box_width[i], #ширина прямоугольника\n",
    "            box_height[i], #высота прямоугольника\n",
    "            linewidth=3, #ширина линии\n",
    "            edgecolor='r', #цвет\n",
    "            facecolor='none' #заливка (none — отсутствует)\n",
    "        )\n",
    "        # Накладываем прямоугольник поверх изображения\n",
    "        ax.add_patch(rect);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bounding_box(image_folder=IMAGES_PATH, image_filename='Cars330.png', df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 3\n",
    "for i in range(count):\n",
    "    random_image_idx = np.random.choice(df.shape[0])\n",
    "    image_filename = df.loc[random_image_idx, 'filename']\n",
    "    plot_bounding_box(IMAGES_PATH, image_filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"dataset/\" # Корневая папка датасета\n",
    "\n",
    "LABELS_PATH = os.path.join(DATA_PATH, \"labels\") # Папка с аннотациями\n",
    "IMGS_PATH = os.path.join(DATA_PATH, \"images\") #Папка с изображениями\n",
    "\n",
    "TRAIN_IMAGES_PATH = os.path.join(IMGS_PATH, \"train\") #Путь до папки с обучающими изображениями\n",
    "VAL_IMAGES_PATH = os.path.join(IMGS_PATH, \"val\") #Путь до папки с валидационными изображениями\n",
    "TRAIN_LABELS_PATH = os.path.join(LABELS_PATH, \"train\") #Путь до папки с обучающими аннотациями\n",
    "VAL_LABELS_PATH = os.path.join(LABELS_PATH, \"val\") #Путь до папки с валидационными аннотациями\n",
    "\n",
    "DATA_CONFIG_PATH = os.path.join(DATA_PATH, \"dataset.yaml\") #Путь до файла конфигураций данных\n",
    "\n",
    "print(TRAIN_IMAGES_PATH)\n",
    "print(VAL_IMAGES_PATH)\n",
    "print(TRAIN_LABELS_PATH)\n",
    "print(VAL_LABELS_PATH)\n",
    "print(DATA_CONFIG_PATH)\n",
    "\n",
    "## dataset/images/train\n",
    "## dataset/images/val\n",
    "## dataset/labels/train\n",
    "## dataset/labels/val\n",
    "## dataset/dataset.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём локальную папку, в которую будем помещать изображения и аннотации к ним (если такая ещё не существует).\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "\n",
    "# Создаём папку, в которой будем хранить обучающие изображения (если такая ещё не существует).    \n",
    "if not os.path.exists(TRAIN_IMAGES_PATH):\n",
    "    os.makedirs(TRAIN_IMAGES_PATH)\n",
    "\n",
    "# Создаём папку, в которой будем хранить обучающие аннотации к объектам (если такая еще не существует).\n",
    "if not os.path.exists(TRAIN_LABELS_PATH):\n",
    "    os.makedirs(TRAIN_LABELS_PATH)\n",
    "\n",
    "# Создаём папку, в которой будем хранить валидационные изображения (если такая ещё не существует).\n",
    "if not os.path.exists(VAL_IMAGES_PATH):\n",
    "    os.makedirs(VAL_IMAGES_PATH)\n",
    "\n",
    "# Создаём папку, в которой будем хранить валидационные аннотации к объектам (если такая ещё не существует).\n",
    "if not os.path.exists(VAL_LABELS_PATH):\n",
    "    os.makedirs(VAL_LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls dataset\n",
    "!ls dataset/images\n",
    "!ls dataset/labels\n",
    "\n",
    "## dataset.yaml  images  labels\n",
    "## train  val\n",
    "## train  val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём содержимое файла\n",
    "data_config = f'''\n",
    "path: /kaggle/working/dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "test:\n",
    "names:\n",
    "    0: licence\n",
    "'''\n",
    "\n",
    "# Открываем на запись файл, в который записываем конфигурацию путей и из которого будут браться данные для обучения.\n",
    "with open(DATA_CONFIG_PATH, 'w') as f:\n",
    "    f.write(data_config)\n",
    "\n",
    "# Проверяем, что всё записалось корректно.\n",
    "with open(DATA_CONFIG_PATH, 'r') as f:\n",
    "    print(f.read())\n",
    "## path: /kaggle/working/dataset\n",
    "## train: images/train\n",
    "## val: images/val\n",
    "## test:\n",
    "## names:\n",
    "##     0: licence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
